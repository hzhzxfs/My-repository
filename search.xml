<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>EDA数据探索性分析</title>
    <url>/2021/04/17/EDA%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<p>EDA——数据探索性分析，是通过了解数据集的基本情况、变量间的相互关系以及变量与预测值之间的关系，为后期特征工程和建立模型做铺垫。本文以<em>智慧海洋建设竞赛</em>为例进行演示。</p>
<h4 id="1-总体了解数据"><a href="#1-总体了解数据" class="headerlink" title="1. 总体了解数据"></a>1. 总体了解数据</h4><h5 id="1-1-查看样本个数和原始特征维度"><a href="#1-1-查看样本个数和原始特征维度" class="headerlink" title="1.1 查看样本个数和原始特征维度"></a>1.1 查看样本个数和原始特征维度</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_train.shape</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_test.shape</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_train.columns	<span class="comment">#查看列名</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pd.set_option(<span class="string">&#x27;display.max_info_rows&#x27;</span>,<span class="number">2699639</span>)	<span class="comment">#提高非缺失值检查的行数上线</span></span><br><span class="line"><span class="comment">#pd.options.display.max_info_rows = 2699639</span></span><br><span class="line">data_train.info()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#查看count 非空值数、std 标准差、（25%、50%、75%）分位数等基本情况</span></span><br><span class="line">data_train.describe([<span class="number">0.01</span>,<span class="number">0.025</span>,<span class="number">0.05</span>,<span class="number">0.5</span>,<span class="number">0.75</span>,<span class="number">0.9</span>,<span class="number">0.99</span>])	</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<h5 id="1-2-查看缺失值和唯一值等"><a href="#1-2-查看缺失值和唯一值等" class="headerlink" title="1.2 查看缺失值和唯一值等"></a>1.2 查看缺失值和唯一值等</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_train.isnull().<span class="built_in">any</span>()	<span class="comment">#查看缺失值</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#查看含有缺失值的列名</span></span><br><span class="line">data_train.columns[data_train.isnull().<span class="built_in">any</span>()].tolist()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#查看仅有唯一值的特征</span></span><br><span class="line">one_value_fea_train = [col <span class="keyword">for</span> col <span class="keyword">in</span> data_train.columns <span class="keyword">if</span> data_train[col].nunique() &lt;= <span class="number">1</span>]</span><br><span class="line">one_value_fea_test = [col <span class="keyword">for</span> col <span class="keyword">in</span> data_test.columns <span class="keyword">if</span> data_test[col].nunique() &lt;= <span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<h4 id="2-查看数据特性和特征分布"><a href="#2-查看数据特性和特征分布" class="headerlink" title="2. 查看数据特性和特征分布"></a>2. 查看数据特性和特征分布</h4><h5 id="2-1-渔船轨迹可视化"><a href="#2-1-渔船轨迹可视化" class="headerlink" title="2.1 渔船轨迹可视化"></a>2.1 渔船轨迹可视化</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 从每个类别中随机抽取三个渔船的轨迹进行可视化</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">visualize_three_traj</span>():</span></span><br><span class="line">    fig,axes = plt.subplots(nrows=<span class="number">3</span>,ncols=<span class="number">3</span>,figsize=(<span class="number">20</span>,<span class="number">15</span>))</span><br><span class="line">    plt.subplots_adjust(wspace=<span class="number">0.2</span>,hspace=<span class="number">0.2</span>)</span><br><span class="line">    <span class="comment"># 对于每一个类别，随机选出刺网的三条轨迹进行可视化</span></span><br><span class="line">    lables = [<span class="string">&quot;ciwang&quot;</span>,<span class="string">&quot;weiwang&quot;</span>,<span class="string">&quot;tuowang&quot;</span>]</span><br><span class="line">    <span class="keyword">for</span> i,file_type <span class="keyword">in</span> tqdm(<span class="built_in">enumerate</span>([<span class="string">&quot;ciwang_data&quot;</span>,<span class="string">&quot;weiwang_data&quot;</span>,<span class="string">&quot;tuowang_data&quot;</span>])):</span><br><span class="line">        data1, data2, data3 = get_random_three_traj(<span class="built_in">type</span>=file_type)</span><br><span class="line">        <span class="keyword">for</span> j, datax <span class="keyword">in</span> <span class="built_in">enumerate</span>([data1, data2, data3]):</span><br><span class="line">            x_data = datax[<span class="string">&quot;x&quot;</span>].loc[-<span class="number">1</span>:].values</span><br><span class="line">            y_data = datax[<span class="string">&quot;y&quot;</span>].loc[-<span class="number">1</span>:].values</span><br><span class="line">            axes[i][j - <span class="number">1</span>].scatter(x_data[<span class="number">0</span>], y_data[<span class="number">0</span>], label=<span class="string">&quot;start&quot;</span>, c=<span class="string">&quot;red&quot;</span>, s=<span class="number">20</span>, marker=<span class="string">&quot;o&quot;</span>)</span><br><span class="line">            axes[i][j - <span class="number">1</span>].plot(x_data, y_data, label=lables[i])</span><br><span class="line">            axes[i][j - <span class="number">1</span>].scatter(x_data[<span class="built_in">len</span>(x_data) - <span class="number">1</span>], y_data[<span class="built_in">len</span>(y_data) - <span class="number">1</span>], label=<span class="string">&quot;end&quot;</span>, c=<span class="string">&quot;green&quot;</span>, s=<span class="number">20</span>,</span><br><span class="line">                                   marker=<span class="string">&quot;D&quot;</span>)</span><br><span class="line">            axes[i][j - <span class="number">1</span>].grid(alpha=<span class="number">2</span>)</span><br><span class="line">            axes[i][j - <span class="number">1</span>].legend(loc=<span class="string">&quot;best&quot;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line">    </span><br><span class="line">visualize_three_traj()</span><br></pre></td></tr></table></figure>
<p>—————-图1——————</p>
<p>从图中可以发现,不同类别的轨迹有一定区分性.</p>
<blockquote>
<p>刺网为规则多边形.</p>
<p>围网为包围的形状.</p>
<p>拖网为点到点,转弯次数少.</p>
</blockquote>
<p>从轨迹数据可以猜测其特征可能为转弯的角度大小\转弯次数\起始点之间的距离和时间\经度和维度变化范围等.</p>
<p>此外,存在一些异常轨迹需要剔除.</p>
<h4 id="3-坐标序列可视化"><a href="#3-坐标序列可视化" class="headerlink" title="3. 坐标序列可视化"></a>3. 坐标序列可视化</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 随机选取某条数据，观察x坐标序列和y坐标序列的变化情况</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">visualize_one_traj_x_y</span>():</span></span><br><span class="line">    fig,axes = plt.subplots(nrows=<span class="number">2</span>,ncols=<span class="number">1</span>,figsize=(<span class="number">10</span>,<span class="number">8</span>))</span><br><span class="line">    plt.subplots_adjust(wspace=<span class="number">0.2</span>,hspace=<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line">    data1 = get_random_one_traj(<span class="built_in">type</span>=<span class="string">&quot;weiwang_data&quot;</span>)</span><br><span class="line">    x = data1[<span class="string">&quot;x&quot;</span>].loc[-<span class="number">1</span>:]</span><br><span class="line">    x = x / <span class="number">10000</span></span><br><span class="line">    </span><br><span class="line">    y = data1[<span class="string">&quot;y&quot;</span>].loc[-<span class="number">1</span>:]</span><br><span class="line">    y = y / <span class="number">10000</span></span><br><span class="line"></span><br><span class="line">    arr1 = np.arange(<span class="built_in">len</span>(x))</span><br><span class="line">    arr2 = np.arange(<span class="built_in">len</span>(y))</span><br><span class="line"></span><br><span class="line">    axes[<span class="number">0</span>].plot(arr1,x,label=<span class="string">&quot;x&quot;</span>)</span><br><span class="line">    axes[<span class="number">1</span>].plot(arr2,y,label=<span class="string">&quot;y&quot;</span>)</span><br><span class="line">    axes[<span class="number">0</span>].grid(alpha=<span class="number">3</span>)</span><br><span class="line">    axes[<span class="number">0</span>].legend(loc=<span class="string">&quot;best&quot;</span>)</span><br><span class="line">    axes[<span class="number">1</span>].grid(alpha=<span class="number">3</span>)</span><br><span class="line">    axes[<span class="number">1</span>].legend(loc=<span class="string">&quot;best&quot;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line">    </span><br><span class="line">visualize_one_traj_x_y()</span><br></pre></td></tr></table></figure>
<p>———-图2———–</p>
<p>由上图可知,存在同一时间段内x\y坐标均未变化,说明可能该时段内渔船正停留在某处.</p>
<h4 id="4-三类渔船速度和方向可视化"><a href="#4-三类渔船速度和方向可视化" class="headerlink" title="4.三类渔船速度和方向可视化"></a>4.三类渔船速度和方向可视化</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 每类轨迹，随机选取某个渔船，可视化速度序列和方向序列</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">visualize_three_traj_speed_direction</span>():</span></span><br><span class="line">    fig,axes = plt.subplots(nrows=<span class="number">3</span>,ncols=<span class="number">2</span>,figsize=(<span class="number">20</span>,<span class="number">15</span>))</span><br><span class="line">    plt.subplots_adjust(wspace=<span class="number">0.1</span>,hspace=<span class="number">0.1</span>)</span><br><span class="line">    <span class="comment"># 随机选出刺网的三条轨迹进行可视化</span></span><br><span class="line">    file_types = [<span class="string">&quot;ciwang_data&quot;</span>,<span class="string">&quot;weiwang_data&quot;</span>,<span class="string">&quot;tuowang_data&quot;</span>]</span><br><span class="line">    speed_types = [<span class="string">&quot;ciwang_speed&quot;</span>,<span class="string">&quot;weiwang_speed&quot;</span>,<span class="string">&quot;tuowang_speed&quot;</span>]</span><br><span class="line">    doirections = [<span class="string">&quot;ciwang_direction&quot;</span>,<span class="string">&quot;weiwang_direction&quot;</span>,<span class="string">&quot;tuowang_direction&quot;</span>]</span><br><span class="line">    colors = [<span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;brown&#x27;</span>]</span><br><span class="line">    <span class="keyword">for</span> i,file_name <span class="keyword">in</span> tqdm(<span class="built_in">enumerate</span>(file_types)):</span><br><span class="line">        datax = get_random_one_traj(<span class="built_in">type</span>=file_name)</span><br><span class="line">        x_data = datax[<span class="string">&quot;速度&quot;</span>].loc[-<span class="number">1</span>:].values</span><br><span class="line">        y_data = datax[<span class="string">&quot;方向&quot;</span>].loc[-<span class="number">1</span>:].values</span><br><span class="line">        axes[i][<span class="number">0</span>].plot(<span class="built_in">range</span>(<span class="built_in">len</span>(x_data)), x_data, label=speed_types[i], color=colors[i])</span><br><span class="line">        axes[i][<span class="number">0</span>].grid(alpha=<span class="number">2</span>)</span><br><span class="line">        axes[i][<span class="number">0</span>].legend(loc=<span class="string">&quot;best&quot;</span>)</span><br><span class="line">        axes[i][<span class="number">1</span>].plot(<span class="built_in">range</span>(<span class="built_in">len</span>(y_data)), y_data, label=doirections[i], color=colors[i])</span><br><span class="line">        axes[i][<span class="number">1</span>].grid(alpha=<span class="number">2</span>)</span><br><span class="line">        axes[i][<span class="number">1</span>].legend(loc=<span class="string">&quot;best&quot;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">visualize_three_traj_speed_direction()</span><br></pre></td></tr></table></figure>
<p>————图3—————-<br>由上图可知,不同分类渔船的轨迹速度某些时段均存在连续的低值情况,说明可能存在某些海上停留点;不同类别渔船的方向变化都很大,可能是海上漂泊导致,作为特征对于类别的区分度低,但也存在方向变化不大的时段,强化了对停留点存在的判断.</p>
<h4 id="5-三类渔船速度和方向的数据分布"><a href="#5-三类渔船速度和方向的数据分布" class="headerlink" title="5.三类渔船速度和方向的数据分布"></a>5.三类渔船速度和方向的数据分布</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 对某一特征进行数据统计</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_data_cummulation</span>(<span class="params"><span class="built_in">type</span>,path,kind,columns</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    type:&quot;ciwang&quot;,&quot;weiwang&quot; or &quot;tuowang&quot;</span></span><br><span class="line"><span class="string">    path:数据路径</span></span><br><span class="line"><span class="string">    kind:&quot;速度&quot;or&quot;方向&quot;</span></span><br><span class="line"><span class="string">    columns:与kind对应，&quot;speed&quot;or&quot;direction&quot;</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    data_dict = <span class="built_in">dict</span>()</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(path + <span class="built_in">type</span>+<span class="string">&quot;.pkl&quot;</span>,<span class="string">&quot;rb&quot;</span>) <span class="keyword">as</span> file:</span><br><span class="line">        data_list = pickle.load(file)</span><br><span class="line">    <span class="keyword">for</span> datax <span class="keyword">in</span> tqdm(data_list):</span><br><span class="line">        data = datax[kind].values</span><br><span class="line">        <span class="keyword">for</span> speed <span class="keyword">in</span> data:</span><br><span class="line">            data_dict.setdefault(speed,<span class="number">0</span>)</span><br><span class="line">            data_dict[speed] += <span class="number">1</span></span><br><span class="line">    data_dict = <span class="built_in">dict</span>(<span class="built_in">sorted</span>(data_dict.items(),key=<span class="keyword">lambda</span> x:x[<span class="number">0</span>],reverse=<span class="literal">False</span>))</span><br><span class="line">    data_df = pd.DataFrame.from_dict(data_dict,columns=[columns],orient=<span class="string">&quot;index&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> data_df</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 分别得到速度和方向的分布数据</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_speed_and_direction_distribution_data</span>(<span class="params"><span class="built_in">type</span></span>):</span></span><br><span class="line">    path = <span class="string">&quot;./data/&quot;</span></span><br><span class="line">    data_speed_df = get_data_cummulation(<span class="built_in">type</span>=<span class="built_in">type</span>, path=path,kind=<span class="string">&quot;速度&quot;</span>,columns=<span class="string">&quot;speed&quot;</span>)</span><br><span class="line">    data_direction_df = get_data_cummulation(<span class="built_in">type</span>=<span class="built_in">type</span>,path=path,kind=<span class="string">&quot;方向&quot;</span>,columns=<span class="string">&quot;direction&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> data_speed_df,data_direction_df</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 可视化速度和方向的数据分布</span></span><br><span class="line">df_speeds = []</span><br><span class="line">df_directions = []</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_speed_direction1_distribution</span>():</span></span><br><span class="line">    plt.subplots(nrows=<span class="number">1</span>, ncols=<span class="number">2</span>, figsize=(<span class="number">15</span>, <span class="number">6</span>))</span><br><span class="line">    plt.subplots_adjust(wspace=<span class="number">0.2</span>, hspace=<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line">    file_types = [<span class="string">&quot;ciwang_data&quot;</span>, <span class="string">&quot;weiwang_data&quot;</span>, <span class="string">&quot;tuowang_data&quot;</span>]</span><br><span class="line">    lables = [<span class="string">&quot;ciwang&quot;</span>, <span class="string">&quot;weiwang&quot;</span>, <span class="string">&quot;tuowang&quot;</span>]</span><br><span class="line">    colors = [<span class="string">&quot;red&quot;</span>, <span class="string">&quot;blue&quot;</span>, <span class="string">&quot;green&quot;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, filenames <span class="keyword">in</span> <span class="built_in">enumerate</span>(file_types):</span><br><span class="line">        df11, df21 = get_speed_and_direction_distribution_data(file_types[i])</span><br><span class="line">        plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">        ax1 = sns.kdeplot(df11[<span class="string">&quot;speed&quot;</span>].values / <span class="number">1000000</span>, color=colors[i],shade=<span class="literal">True</span>)</span><br><span class="line">        plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">        ax3 = sns.kdeplot(df21[<span class="string">&quot;direction&quot;</span>].values / <span class="number">1000000</span>, color=colors[i],shade=<span class="literal">True</span>)</span><br><span class="line">        df_speeds.append(df11)</span><br><span class="line">        df_directions.append(df21)</span><br><span class="line">    ax1.legend(lables)</span><br><span class="line">    ax1.set_xlabel(<span class="string">&quot;Speed&quot;</span>)</span><br><span class="line">    ax3.set_xlabel(<span class="string">&quot;Direction&quot;</span>)</span><br><span class="line">    ax3.legend(lables)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">plot_speed_direction1_distribution()</span><br></pre></td></tr></table></figure>
<p>———–图4———————</p>
<p>由上图可知,三种类别渔船的速度分布差异较大,而刺网和围网方向分布差异不明显,拖网方向分布有差异.</p>
]]></content>
      <categories>
        <category>Exploratory Data Analysis</category>
        <category>Pandas</category>
        <category>geospatial data analysis</category>
        <category>data visualization</category>
        <category>GIS</category>
      </categories>
      <tags>
        <tag>DataFrame</tag>
      </tags>
  </entry>
  <entry>
    <title>Pandas的一些常用操作_2</title>
    <url>/2021/02/21/pandas_2/</url>
    <content><![CDATA[<blockquote>
<p>今天继续介绍几个常用的Pandas操作。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;./economics.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="1-DataFrame的apply方法"><a href="#1-DataFrame的apply方法" class="headerlink" title="1.DataFrame的apply方法"></a>1.DataFrame的apply方法</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[[<span class="string">&#x27;psavert&#x27;</span>,<span class="string">&#x27;uempmed&#x27;</span>]].apply(<span class="keyword">lambda</span> x:x.<span class="built_in">max</span>()-x.<span class="built_in">min</span>(), axis=<span class="number">1</span>)<span class="comment">#axis=1 将函数应用到列</span></span><br></pre></td></tr></table></figure>
<span id="more"></span>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.applymap(<span class="keyword">lambda</span> x:x*<span class="number">10</span>)<span class="comment">#applymap 将函数应用到每个元素</span></span><br></pre></td></tr></table></figure>
<h4 id="2-DataFrame的分组"><a href="#2-DataFrame的分组" class="headerlink" title="2.DataFrame的分组"></a>2.DataFrame的分组</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.groupby(<span class="string">&#x27;unemploy&#x27;</span>)[<span class="string">&#x27;psavert&#x27;</span>].median()<span class="comment">#样例:df.groupby(分组依据)[数据来源].使用操作</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">condition = df.unemploy &gt; df.unemploy.mean()<span class="comment">#使用condition定义分组依据</span></span><br><span class="line">df.groupby(condition)[<span class="string">&#x27;psavert&#x27;</span>].mean()<span class="comment">#分为True和False两组</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.groupby([condition, df[<span class="string">&#x27;unemploy&#x27;</span>]])[<span class="string">&#x27;psavert&#x27;</span>].mean()<span class="comment">#True组和False两组分别细分</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.groupby([df[<span class="string">&#x27;unemploy&#x27;</span>], df[<span class="string">&#x27;uempmed&#x27;</span>]])[<span class="string">&#x27;psavert&#x27;</span>].mean()<span class="comment">#两级分组</span></span><br></pre></td></tr></table></figure>
<hr>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">gb = df.groupby([<span class="string">&#x27;unemploy&#x27;</span>])<span class="comment">#Groupby对象</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">gb.size()<span class="comment">#每组的元素个数</span></span><br><span class="line"><span class="comment">#和DataFrame一样，Groupby对象也有max\idxmin\all\\nunique\quantile\prod等函数，这里不一一列举。</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">gb.agg([<span class="string">&#x27;skew&#x27;</span>, <span class="string">&#x27;sum&#x27;</span>, <span class="string">&#x27;idxmax&#x27;</span>])<span class="comment">#agg聚合函数，查看每个分组的三个统计量</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">gb.agg(<span class="keyword">lambda</span> x: x.mean()-x.<span class="built_in">min</span>())<span class="comment">#在agg中自定义函数</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">gb.<span class="built_in">filter</span>(<span class="keyword">lambda</span> x: x.shape[<span class="number">0</span>] &gt; <span class="number">100</span>)<span class="comment">#组过滤</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">gb.apply(<span class="keyword">lambda</span> x: x**<span class="number">2</span>)<span class="comment">#组的apply方法</span></span><br></pre></td></tr></table></figure>
<h4 id="3-DataFrame的连接"><a href="#3-DataFrame的连接" class="headerlink" title="3.DataFrame的连接"></a>3.DataFrame的连接</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df1 = df[<span class="number">0</span>:<span class="number">10</span>]</span><br><span class="line">df2 = df[<span class="number">10</span>:<span class="number">20</span>]</span><br><span class="line">df1.merge(df2, on=<span class="string">&#x27;date&#x27;</span>, how=<span class="string">&#x27;outer&#x27;</span>)<span class="comment">#merge表示关系型连接，包括左连接、右连接、内连接和外(全)连接</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pd.concat([df1, df2], axis=<span class="number">0</span>)<span class="comment">#concat是方向性连接，axis=0表示纵向连接</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">choose_min</span>(<span class="params">x1, x2</span>):</span></span><br><span class="line">    <span class="built_in">min</span> = x1.where(x1&lt;x2, x1)</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">min</span></span><br><span class="line">df1.combine(df2, choose_min)<span class="comment">#使用combine函数自定义连接规则</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>下一期是Pandas的常见数据处理，包括缺失数据、文本数据、分类数据和时序数据。</p>
</blockquote>
]]></content>
      <categories>
        <category>Pandas</category>
      </categories>
      <tags>
        <tag>DataFrame</tag>
      </tags>
  </entry>
  <entry>
    <title>Pandas的一些常用操作_1</title>
    <url>/2021/02/21/pandas_1/</url>
    <content><![CDATA[<blockquote>
<p>今天介绍几个常用的Pandas操作。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;./economics.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="1-DataFrame-to-markdown-latex"><a href="#1-DataFrame-to-markdown-latex" class="headerlink" title="1.DataFrame to markdown/latex"></a>1.DataFrame to markdown/latex</h4><p>dataframe可以转换为许多常用格式，如csv,excel,sql,json,html,latex等等，这里以markdown和latex为例。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(df.to_markdown())</span><br><span class="line"><span class="built_in">print</span>(df.to_latex())</span><br></pre></td></tr></table></figure>
<p>or</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.to_markdown(<span class="string">&#x27;table.md&#x27;</span>)</span><br><span class="line">df.to_latex(<span class="string">&#x27;table.tex&#x27;</span>)</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<p>也可以自定义输出latex格式，如表格宽度。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.to_latex(<span class="string">&#x27;tb.tex&#x27;</span>,column_format=<span class="string">&#x27;lp&#123;1.8cm&#125;p&#123;1.8cm&#125;p&#123;1.8cm&#125;p&#123;1.8cm&#125;p&#123;1.8cm&#125;p&#123;1.8cm&#125;&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>除此以外，dataframe还可以保存为图片。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> dataframe_image <span class="keyword">as</span> dfi</span><br><span class="line">dfi.export(obj = df, filename = <span class="string">&#x27;table.jpg&#x27;</span>, fontsize=<span class="number">15</span>)</span><br></pre></td></tr></table></figure>
<h4 id="2-DataFrame常用属性查询"><a href="#2-DataFrame常用属性查询" class="headerlink" title="2.DataFrame常用属性查询"></a>2.DataFrame常用属性查询</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.values	<span class="comment">#值</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.index	<span class="comment">#索引号</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.columns	<span class="comment">#列标签</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.dtypes	<span class="comment">#数据类型</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.shape	<span class="comment">#形状(几行几列)</span></span><br></pre></td></tr></table></figure>
<h4 id="3-DataFrame常用基本函数"><a href="#3-DataFrame常用基本函数" class="headerlink" title="3.DataFrame常用基本函数"></a>3.DataFrame常用基本函数</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.head(<span class="number">5</span>)	<span class="comment">#前5行</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.tail(<span class="number">5</span>)	<span class="comment">#后5行</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.info()	<span class="comment">#信息概况</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.describe()	<span class="comment">#主要统计量(count、mean、std、max、min、quartile)</span></span><br></pre></td></tr></table></figure>
<h4 id="4-DataFrame唯一值函数"><a href="#4-DataFrame唯一值函数" class="headerlink" title="4.DataFrame唯一值函数"></a>4.DataFrame唯一值函数</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[<span class="string">&#x27;psavert&#x27;</span>].unique()	<span class="comment">#唯一值组成的数组</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[<span class="string">&#x27;psavert&#x27;</span>].nunique()    <span class="comment">#唯一值个数</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[<span class="string">&#x27;psavert&#x27;</span>].value_counts()    <span class="comment">#唯一值及其频数</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.describe()    <span class="comment">#主要统计量(count、mean、std、max、min、quartile)</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[<span class="string">&#x27;psavert&#x27;</span>].duplicated()    <span class="comment">#重复行的布尔值</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[df[<span class="string">&#x27;psavert&#x27;</span>].duplicated()]    <span class="comment">#单列去重(删除重复行)</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.drop_duplicates(subset=[<span class="string">&#x27;psavert&#x27;</span>, <span class="string">&#x27;pop&#x27;</span>], keep=<span class="string">&#x27;first&#x27;</span>)    <span class="comment">#多列去重(保留first唯一值)</span></span><br></pre></td></tr></table></figure>
<h4 id="5-DataFrame替换函数"><a href="#5-DataFrame替换函数" class="headerlink" title="5.DataFrame替换函数"></a>5.DataFrame替换函数</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[<span class="string">&#x27;psavert&#x27;</span>].replace(<span class="number">12.5</span>, <span class="string">&#x27;A&#x27;</span>, inplace = <span class="literal">True</span>)    <span class="comment">#替换某列的单个值</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[<span class="string">&#x27;psavert&#x27;</span>].replace(&#123;<span class="number">12.5</span>:<span class="string">&#x27;A&#x27;</span>, <span class="number">11.7</span>:<span class="string">&#x27;B&#x27;</span>&#125;, inplace = <span class="literal">True</span>)    <span class="comment">#替换某列的多个值</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[<span class="string">&#x27;date&#x27;</span>].replace(&#123;<span class="string">r&#x27;2\d+&#x27;</span>: <span class="string">&#x27;The 21st century&#x27;</span>&#125;, regex=<span class="literal">True</span>, inplace = <span class="literal">True</span>)    <span class="comment">#正则替换</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[<span class="string">&#x27;psavert&#x27;</span>].mask(df[<span class="string">&#x27;psavert&#x27;</span>]&gt;<span class="number">12.0</span> ,<span class="string">&#x27;A&#x27;</span>, inplace = <span class="literal">True</span>)    <span class="comment">#条件符合，进行替换</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[<span class="string">&#x27;psavert&#x27;</span>].where(df[<span class="string">&#x27;psavert&#x27;</span>]&lt;<span class="number">12.0</span> ,<span class="string">&#x27;A&#x27;</span>, inplace = <span class="literal">True</span>)    <span class="comment">#条件不符合，进行替换</span></span><br></pre></td></tr></table></figure>
<h4 id="5-DataFrame排序函数"><a href="#5-DataFrame排序函数" class="headerlink" title="5.DataFrame排序函数"></a>5.DataFrame排序函数</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.sort_values(<span class="string">&#x27;psavert&#x27;</span>,ascending = <span class="literal">False</span>)    <span class="comment">#单列降序排序</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.sort_values([<span class="string">&#x27;psavert&#x27;</span>,<span class="string">&#x27;uempmed&#x27;</span>],ascending=[<span class="literal">True</span>,<span class="literal">False</span>])    <span class="comment">#前者升序情况下，后降序</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>今天先写到这，下一期接着写DataFrame的apply方法。</p>
</blockquote>
]]></content>
      <categories>
        <category>Pandas</category>
      </categories>
      <tags>
        <tag>DataFrame</tag>
      </tags>
  </entry>
  <entry>
    <title>LightGBM调参_1</title>
    <url>/2021/03/26/lightGBM%E8%B0%83%E5%8F%82/</url>
    <content><![CDATA[<p>#1简单列举一下日常调参过程中常用的几种方法，具体的原理下次补上。</p>
<h4 id="1-经验法"><a href="#1-经验法" class="headerlink" title="1. 经验法:"></a>1. 经验法:</h4><blockquote>
<p>往两个方向调：</p>
<p>1.提高准确率：max_depth, num_leaves, learning_rate</p>
<p>2.降低过拟合：max_bin, min_data_in_leaf；L1, L2正则化；数据抽样, 列采样</p>
</blockquote>
<p>1.使用较小的num_leaves，max_depth和max_bin，降低复杂度。</p>
<p>2.使用min_data_in_leaf和min_sum_hessian_in_leaf，该值越大，模型的学习越保守。</p>
<span id="more"></span>

<p>3.设置bagging_freq和bagging_fraction使用bagging。</p>
<p>4.设置feature_fraction进行特征采样。</p>
<p>5.使用lambda_l1,lambda_l2和min_gain_to_split正则化。</p>
<h4 id="2-贪心调参"><a href="#2-贪心调参" class="headerlink" title="2. 贪心调参:"></a>2. 贪心调参:</h4><p>先调整对模型影响最大的参数，再调整对模型影响次大的参数，缺点是容易调成局部最优，需要多次调试。日常调参顺序如下:</p>
<p>① num_leaves, max_depth</p>
<p>② min_data_in_leaf, min_child_weight</p>
<p>③ bagging_freq, bagging_fraction,  feature_fraction,</p>
<p>④ reg_lambda, reg_alpha</p>
<p>⑤ min_split_gain</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="comment"># 调objective</span></span><br><span class="line">best_obj = <span class="built_in">dict</span>()</span><br><span class="line"><span class="keyword">for</span> obj <span class="keyword">in</span> objective:</span><br><span class="line">    model = LGBMRegressor(objective=obj)</span><br><span class="line">    score = cross_val_score(model, X_train, y_train, cv=<span class="number">5</span>, scoring=<span class="string">&#x27;f1&#x27;</span>).mean()</span><br><span class="line">    best_obj[obj] = score</span><br><span class="line"></span><br><span class="line"><span class="comment"># num_leaves</span></span><br><span class="line">best_leaves = <span class="built_in">dict</span>()</span><br><span class="line"><span class="keyword">for</span> leaves <span class="keyword">in</span> num_leaves:</span><br><span class="line">    model = LGBMRegressor(objective=<span class="built_in">min</span>(best_obj.items(), key=<span class="keyword">lambda</span> x:x[<span class="number">1</span>])[<span class="number">0</span>], num_leaves=leaves)</span><br><span class="line">    score = cross_val_score(model, X_train, y_train, cv=<span class="number">5</span>, scoring=<span class="string">&#x27;f1&#x27;</span>).mean()</span><br><span class="line">    best_leaves[leaves] = score</span><br><span class="line"></span><br><span class="line"><span class="comment"># max_depth</span></span><br><span class="line">best_depth = <span class="built_in">dict</span>()</span><br><span class="line"><span class="keyword">for</span> depth <span class="keyword">in</span> max_depth:</span><br><span class="line">    model = LGBMRegressor(objective=<span class="built_in">min</span>(best_obj.items(), key=<span class="keyword">lambda</span> x:x[<span class="number">1</span>])[<span class="number">0</span>],</span><br><span class="line">                          num_leaves=<span class="built_in">min</span>(best_leaves.items(), key=<span class="keyword">lambda</span> x:x[<span class="number">1</span>])[<span class="number">0</span>],</span><br><span class="line">                          max_depth=depth)</span><br><span class="line">    score = cross_val_score(model, X_train, y_train, cv=<span class="number">5</span>, scoring=<span class="string">&#x27;f1&#x27;</span>).mean()</span><br><span class="line">    best_depth[depth] = score</span><br></pre></td></tr></table></figure>

<p>以此类推，按调参顺序依次调整优化，并且可以对每一个最优参数下模型的得分进行可视化。</p>
<h4 id="3-网格搜索"><a href="#3-网格搜索" class="headerlink" title="3. 网格搜索"></a>3. 网格搜索</h4><p>即穷举搜索，在参数数组里循环遍历，一般大数据集不会用到，因为速度太慢。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_best_cv_params</span>(<span class="params">learning_rate=<span class="number">0.1</span>, n_estimators=<span class="number">581</span>, num_leaves=<span class="number">31</span>, max_depth=-<span class="number">1</span>, bagging_fraction=<span class="number">1.0</span>, feature_fraction=<span class="number">1.0</span>, bagging_freq=<span class="number">0</span>, min_data_in_leaf=<span class="number">20</span>, min_child_weight=<span class="number">0.001</span>, min_split_gain=<span class="number">0</span>, reg_lambda=<span class="number">0</span>, reg_alpha=<span class="number">0</span>, param_grid=<span class="literal">None</span></span>):</span></span><br><span class="line"></span><br><span class="line">    cv_fold = KFold(n_splits=<span class="number">5</span>, shuffle=<span class="literal">True</span>, random_state=<span class="number">2021</span>)</span><br><span class="line"></span><br><span class="line">    model_lgb = lgb.LGBMClassifier(learning_rate=learning_rate,</span><br><span class="line">                                   n_estimators=n_estimators,</span><br><span class="line">                                   num_leaves=num_leaves,</span><br><span class="line">                                   max_depth=max_depth,</span><br><span class="line">                                   bagging_fraction=bagging_fraction,</span><br><span class="line">                                   feature_fraction=feature_fraction,</span><br><span class="line">                                   bagging_freq=bagging_freq,</span><br><span class="line">                                   min_data_in_leaf=min_data_in_leaf,</span><br><span class="line">                                   min_child_weight=min_child_weight,</span><br><span class="line">                                   min_split_gain=min_split_gain,</span><br><span class="line">                                   reg_lambda=reg_lambda,</span><br><span class="line">                                   reg_alpha=reg_alpha,</span><br><span class="line">                                   n_jobs= <span class="number">8</span></span><br><span class="line">                                  )</span><br><span class="line"></span><br><span class="line">    f1 = make_scorer(f1_score, average=<span class="string">&#x27;micro&#x27;</span>)</span><br><span class="line">    grid_search = GridSearchCV(estimator=model_lgb, </span><br><span class="line">                               cv=cv_fold,</span><br><span class="line">                               param_grid=param_grid,</span><br><span class="line">                               scoring=f1</span><br><span class="line"></span><br><span class="line">                              )</span><br><span class="line">    grid_search.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;模型当前最优参数为:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(grid_search.best_params_))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;模型当前最优得分为:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(grid_search.best_score_))</span><br></pre></td></tr></table></figure>
<p>总体思路是先粗调再细调。在一开始调整时，可设置较大的学习率如0.1，先确定树的个数，再依次调整参数，最后设置较小的学习率如0.05，确定最终参数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lgb_params = &#123;<span class="string">&#x27;num_leaves&#x27;</span>: <span class="built_in">range</span>(<span class="number">10</span>, <span class="number">80</span>, <span class="number">5</span>), <span class="string">&#x27;max_depth&#x27;</span>: <span class="built_in">range</span>(<span class="number">3</span>,<span class="number">10</span>,<span class="number">2</span>)&#125;</span><br><span class="line">get_best_cv_params()</span><br><span class="line"><span class="comment">#----------------------------------------</span></span><br><span class="line">lgb_params = &#123;<span class="string">&#x27;num_leaves&#x27;</span>: <span class="built_in">range</span>(<span class="number">25</span>, <span class="number">35</span>, <span class="number">1</span>), <span class="string">&#x27;max_depth&#x27;</span>: <span class="built_in">range</span>(<span class="number">5</span>,<span class="number">9</span>,<span class="number">1</span>)&#125;</span><br><span class="line">get_best_cv_params(n_estimators=<span class="number">85</span>)</span><br><span class="line"><span class="comment">#----------------------------------------</span></span><br><span class="line">lgb_params = &#123;<span class="string">&#x27;bagging_fraction&#x27;</span>: [i/<span class="number">10</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>,<span class="number">10</span>,<span class="number">1</span>)], </span><br><span class="line">              <span class="string">&#x27;feature_fraction&#x27;</span>: [i/<span class="number">10</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>,<span class="number">10</span>,<span class="number">1</span>)],</span><br><span class="line">              <span class="string">&#x27;bagging_freq&#x27;</span>: <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">81</span>,<span class="number">10</span>)&#125;</span><br><span class="line">get_best_cv_params(n_estimators=<span class="number">85</span>, num_leaves=<span class="number">29</span>, max_depth=<span class="number">7</span>, min_data_in_leaf=<span class="number">45</span>）</span><br><span class="line"><span class="comment">#----------------------------------------</span></span><br><span class="line">lgb_params = &#123;<span class="string">&#x27;reg_lambda&#x27;</span>: [<span class="number">0</span>,<span class="number">0.001</span>,<span class="number">0.01</span>,<span class="number">0.03</span>,<span class="number">0.08</span>,<span class="number">0.3</span>,<span class="number">0.5</span>], <span class="string">&#x27;reg_alpha&#x27;</span>: [<span class="number">0</span>,<span class="number">0.001</span>,<span class="number">0.01</span>,<span class="number">0.03</span>,<span class="number">0.08</span>,<span class="number">0.3</span>,<span class="number">0.5</span>]&#125;</span><br><span class="line">get_best_cv_params(n_estimators=<span class="number">85</span>, num_leaves=<span class="number">29</span>, max_depth=<span class="number">7</span>, min_data_in_leaf=<span class="number">45</span>, bagging_fraction=<span class="number">0.9</span>, feature_fraction=<span class="number">0.9</span>, bagging_freq=<span class="number">40</span>)</span><br><span class="line"><span class="comment">#----------------------------------------</span></span><br><span class="line">lgb_params = &#123;<span class="string">&#x27;min_split_gain&#x27;</span>: [i/<span class="number">10</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">11</span>,<span class="number">1</span>)]&#125;</span><br><span class="line">get_best_cv_params(n_estimators=<span class="number">85</span>, num_leaves=<span class="number">29</span>, max_depth=<span class="number">7</span>, min_data_in_leaf=<span class="number">45</span>, bagging_fraction=<span class="number">0.9</span>, feature_fraction=<span class="number">0.9</span>, bagging_freq=<span class="number">40</span>, min_split_gain=<span class="literal">None</span>)</span><br><span class="line"><span class="comment">#----------------------------------------</span></span><br><span class="line">final_params = &#123;</span><br><span class="line">                <span class="string">&#x27;boosting_type&#x27;</span>: <span class="string">&#x27;gbdt&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;learning_rate&#x27;</span>: <span class="number">0.01</span>,</span><br><span class="line">                <span class="string">&#x27;num_leaves&#x27;</span>: <span class="number">29</span>,</span><br><span class="line">                <span class="string">&#x27;max_depth&#x27;</span>: <span class="number">7</span>,</span><br><span class="line">                <span class="string">&#x27;objective&#x27;</span>: <span class="string">&#x27;multiclass&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;num_class&#x27;</span>: <span class="number">4</span>,</span><br><span class="line">                <span class="string">&#x27;min_data_in_leaf&#x27;</span>:<span class="number">45</span>,</span><br><span class="line">                <span class="string">&#x27;min_child_weight&#x27;</span>:<span class="number">0.001</span>,</span><br><span class="line">                <span class="string">&#x27;bagging_fraction&#x27;</span>: <span class="number">0.9</span>,</span><br><span class="line">                <span class="string">&#x27;feature_fraction&#x27;</span>: <span class="number">0.9</span>,</span><br><span class="line">                <span class="string">&#x27;bagging_freq&#x27;</span>: <span class="number">40</span>,</span><br><span class="line">                <span class="string">&#x27;min_split_gain&#x27;</span>: <span class="number">0</span>,</span><br><span class="line">                <span class="string">&#x27;reg_lambda&#x27;</span>:<span class="number">0</span>,</span><br><span class="line">                <span class="string">&#x27;reg_alpha&#x27;</span>:<span class="number">0</span>,</span><br><span class="line">                <span class="string">&#x27;nthread&#x27;</span>: <span class="number">6</span></span><br><span class="line">               &#125;</span><br><span class="line"></span><br><span class="line">cv_result = lgb.cv(train_set=lgb_train,</span><br><span class="line">                   early_stopping_rounds=<span class="number">20</span>,</span><br><span class="line">                   num_boost_round=<span class="number">5000</span>,</span><br><span class="line">                   nfold=<span class="number">5</span>,</span><br><span class="line">                   stratified=<span class="literal">True</span>,</span><br><span class="line">                   shuffle=<span class="literal">True</span>,</span><br><span class="line">                   params=final_params,</span><br><span class="line">                   feval=f1_score_vali,</span><br><span class="line">                   seed=<span class="number">0</span>,</span><br><span class="line">                  )</span><br></pre></td></tr></table></figure>
<h4 id="4-贝叶斯调参"><a href="#4-贝叶斯调参" class="headerlink" title="4. 贝叶斯调参"></a>4. 贝叶斯调参</h4><p>是一种用模型找到目标函数最小值的方法，比网格和随机搜索省时。步骤如下：</p>
<p>① 定义优化函数(rf_cv）</p>
<p>② 建立模型</p>
<p>③ 定义待优化的参数</p>
<p>④ 得到优化结果，并返回要优化的分数指标</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="comment">#定义优化函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rf_cv_lgb</span>(<span class="params">num_leaves, max_depth, bagging_fraction, feature_fraction, bagging_freq, min_data_in_leaf, </span></span></span><br><span class="line"><span class="function"><span class="params">              min_child_weight, min_split_gain, reg_lambda, reg_alpha</span>):</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立模型</span></span><br><span class="line">    model_lgb = lgb.LGBMClassifier(boosting_type=<span class="string">&#x27;gbdt&#x27;</span>, objective=<span class="string">&#x27;multiclass&#x27;</span>, num_class=<span class="number">4</span>,learning_rate=<span class="number">0.1</span>, n_estimators=<span class="number">5000</span>,num_leaves=<span class="built_in">int</span>(num_leaves), max_depth=<span class="built_in">int</span>(max_depth), bagging_fraction=<span class="built_in">round</span>(bagging_fraction, <span class="number">2</span>), feature_fraction=<span class="built_in">round</span>(feature_fraction, <span class="number">2</span>),bagging_freq=<span class="built_in">int</span>(bagging_freq), min_data_in_leaf=<span class="built_in">int</span>(min_data_in_leaf),min_child_weight=min_child_weight)</span><br><span class="line">    f1 = make_scorer(f1_score, average=<span class="string">&#x27;micro&#x27;</span>)</span><br><span class="line">    val = cross_val_score(model_lgb, X_train_split, y_train_split, cv=<span class="number">5</span>, scoring=f1).mean()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> val</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> bayes_opt <span class="keyword">import</span> BayesianOptimization</span><br><span class="line"><span class="comment">#定义优化参数</span></span><br><span class="line">bayes_lgb = BayesianOptimization(</span><br><span class="line">    rf_cv_lgb, </span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&#x27;num_leaves&#x27;</span>:(<span class="number">10</span>, <span class="number">200</span>),</span><br><span class="line">        <span class="string">&#x27;max_depth&#x27;</span>:(<span class="number">3</span>, <span class="number">20</span>),</span><br><span class="line">        <span class="string">&#x27;bagging_fraction&#x27;</span>:(<span class="number">0.5</span>, <span class="number">1.0</span>),</span><br><span class="line">        <span class="string">&#x27;feature_fraction&#x27;</span>:(<span class="number">0.5</span>, <span class="number">1.0</span>),</span><br><span class="line">        <span class="string">&#x27;bagging_freq&#x27;</span>:(<span class="number">0</span>, <span class="number">100</span>),</span><br><span class="line">        <span class="string">&#x27;min_data_in_leaf&#x27;</span>:(<span class="number">10</span>,<span class="number">100</span>),</span><br><span class="line">        <span class="string">&#x27;min_child_weight&#x27;</span>:(<span class="number">0</span>, <span class="number">10</span>),</span><br><span class="line">        <span class="string">&#x27;min_split_gain&#x27;</span>:(<span class="number">0.0</span>, <span class="number">1.0</span>),</span><br><span class="line">        <span class="string">&#x27;reg_alpha&#x27;</span>:(<span class="number">0.0</span>, <span class="number">10</span>),</span><br><span class="line">        <span class="string">&#x27;reg_lambda&#x27;</span>:(<span class="number">0.0</span>, <span class="number">10</span>),</span><br><span class="line">    &#125;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">#开始优化</span></span><br><span class="line">bayes_lgb.maximize(n_iter=<span class="number">20</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#显示优化结果</span></span><br><span class="line">bayes_lgb.<span class="built_in">max</span></span><br></pre></td></tr></table></figure>

<p>参数优化完成后，可根据优化后的参数建立新的模型，降低学习率并寻找最优模型迭代次数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#设置较小的学习率，并通过cv函数确定当前最优的迭代次数</span></span><br><span class="line">base_params_lgb = &#123;</span><br><span class="line">                    <span class="string">&#x27;boosting_type&#x27;</span>: <span class="string">&#x27;gbdt&#x27;</span>,</span><br><span class="line">                    <span class="string">&#x27;objective&#x27;</span>: <span class="string">&#x27;multiclass&#x27;</span>,</span><br><span class="line">                    <span class="string">&#x27;num_class&#x27;</span>: <span class="number">4</span>,</span><br><span class="line">                    <span class="string">&#x27;learning_rate&#x27;</span>: <span class="number">0.01</span>,</span><br><span class="line">                    <span class="string">&#x27;num_leaves&#x27;</span>: <span class="number">138</span>,</span><br><span class="line">                    <span class="string">&#x27;max_depth&#x27;</span>: <span class="number">11</span>,</span><br><span class="line">                    <span class="string">&#x27;min_data_in_leaf&#x27;</span>: <span class="number">43</span>,</span><br><span class="line">                    <span class="string">&#x27;min_child_weight&#x27;</span>: <span class="number">6.5</span>,</span><br><span class="line">                    <span class="string">&#x27;bagging_fraction&#x27;</span>: <span class="number">0.64</span>,</span><br><span class="line">                    <span class="string">&#x27;feature_fraction&#x27;</span>: <span class="number">0.93</span>,</span><br><span class="line">                    <span class="string">&#x27;bagging_freq&#x27;</span>: <span class="number">49</span>,</span><br><span class="line">                    <span class="string">&#x27;reg_lambda&#x27;</span>: <span class="number">7</span>,</span><br><span class="line">                    <span class="string">&#x27;reg_alpha&#x27;</span>: <span class="number">0.21</span>,</span><br><span class="line">                    <span class="string">&#x27;min_split_gain&#x27;</span>: <span class="number">0.288</span>,</span><br><span class="line">                    <span class="string">&#x27;nthread&#x27;</span>: <span class="number">10</span>,</span><br><span class="line">                    <span class="string">&#x27;verbose&#x27;</span>: -<span class="number">1</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">cv_result_lgb = lgb.cv(</span><br><span class="line">    train_set=train_matrix,</span><br><span class="line">    early_stopping_rounds=<span class="number">1000</span>, </span><br><span class="line">    num_boost_round=<span class="number">20000</span>,</span><br><span class="line">    nfold=<span class="number">5</span>,</span><br><span class="line">    stratified=<span class="literal">True</span>,</span><br><span class="line">    shuffle=<span class="literal">True</span>,</span><br><span class="line">    params=base_params_lgb,</span><br><span class="line">    feval=f1_score_vali,</span><br><span class="line">    seed=<span class="number">0</span></span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;迭代次数&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(cv_result_lgb[<span class="string">&#x27;f1_score-mean&#x27;</span>])))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;最终模型的f1为&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">max</span>(cv_result_lgb[<span class="string">&#x27;f1_score-mean&#x27;</span>])))</span><br></pre></td></tr></table></figure>

<p>模型参数确定之后，建立最终模型并对验证集进行验证。</p>
]]></content>
      <categories>
        <category>Machine learning</category>
      </categories>
      <tags>
        <tag>Grid search</tag>
        <tag>Bayesian optimization</tag>
        <tag>Cross validation</tag>
      </tags>
  </entry>
  <entry>
    <title>Pandas的一些常用操作_3</title>
    <url>/2021/02/21/pandas_3/</url>
    <content><![CDATA[<blockquote>
<p>今天介绍Pandas对一些常见数据的处理方法。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;./economics.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="1-缺失数据处理"><a href="#1-缺失数据处理" class="headerlink" title="1.缺失数据处理"></a>1.缺失数据处理</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.isna()<span class="comment">#是否有缺失值</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.isna().mean()<span class="comment">#缺失的比例 </span></span><br></pre></td></tr></table></figure>
<span id="more"></span>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[df.psavert.isna()]<span class="comment">#查看某列是否有缺失值</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[df[[<span class="string">&#x27;psavert&#x27;</span>,<span class="string">&#x27;pop&#x27;</span>,<span class="string">&#x27;uempmed&#x27;</span>]].isna().<span class="built_in">any</span>(<span class="number">1</span>)]<span class="comment">#查看所有列至少有一个缺失值的行“any()至少有一个为空,all()都为空”</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[df[[<span class="string">&#x27;psavert&#x27;</span>,<span class="string">&#x27;pop&#x27;</span>,<span class="string">&#x27;uempmed&#x27;</span>]].notna().<span class="built_in">all</span>(<span class="number">1</span>)]<span class="comment">#查看所有没有缺失值的行</span></span><br><span class="line">df.loc[df[[<span class="string">&#x27;psavert&#x27;</span>,<span class="string">&#x27;pop&#x27;</span>,<span class="string">&#x27;uempmed&#x27;</span>]].notna().<span class="built_in">all</span>(<span class="number">1</span>)]<span class="comment">#查看所有没有缺失值的区域</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.dropna(axis = <span class="number">0</span>, how = <span class="string">&#x27;any&#x27;</span>, subset = [<span class="string">&#x27;psavert&#x27;</span>, <span class="string">&#x27;pop&#x27;</span>])<span class="comment">#axis=0(删除)行,how=&#x27;any&#x27;至少有一个缺失的行</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.dropna(axis = <span class="number">1</span>, thresh = df.shape[<span class="number">0</span>]-<span class="number">5</span>)<span class="comment">#删除超过5个缺失值的列</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.fillna(method = <span class="string">&#x27;ffill&#x27;</span>, limit = <span class="number">1</span>)<span class="comment">#method=&#x27;ffill&#x27;用前面的元素填充/method=&#x27;bfill&#x27;用后面的元素填充,limit=1连续缺失值的最大填充次数为1</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.fillna(df.mean())<span class="comment">#用每列的均值填充</span></span><br></pre></td></tr></table></figure>
<hr>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.interpolate(limit_direction=<span class="string">&#x27;both&#x27;</span>, limit=<span class="number">1</span>)<span class="comment">#用线性插值填充(both为双向限制插值)</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.interpolate(<span class="string">&#x27;nearest&#x27;</span>).values<span class="comment">#用最近邻插值填充</span></span><br></pre></td></tr></table></figure>
<p>此外，也可以<a href="https://blog.csdn.net/wj1298250240/article/details/103600075">使用KNN来填充缺失值</a>。</p>
<h4 id="2-文本数据处理"><a href="#2-文本数据处理" class="headerlink" title="2.文本数据处理"></a>2.文本数据处理</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ts = pd.Series(df[<span class="string">&#x27;Area&#x27;</span>].values, index=df[<span class="string">&#x27;pct_2014&#x27;</span>])<span class="comment">#DataFrame转换为Series</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ts.<span class="built_in">str</span>[<span class="number">0</span>]<span class="comment">#查看第一个字符</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ts.<span class="built_in">str</span>.<span class="built_in">len</span>()<span class="comment">#查看字符长度</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ts.<span class="built_in">str</span>.split(<span class="string">&#x27;[aon]&#x27;</span>, n=<span class="number">3</span>, expand=<span class="literal">True</span>)<span class="comment">#从左到右拆分字符串，最大拆分次数3次，生成多列</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ts.<span class="built_in">str</span>.join(<span class="string">&#x27;-&#x27;</span>)<span class="comment">#每个字符用“-”连接</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ts.<span class="built_in">str</span>.cat(ts2, sep=<span class="string">&#x27;-&#x27;</span>)<span class="comment">#合并两个字符Series，连接符为“-”</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ts.<span class="built_in">str</span>.contains(<span class="string">&#x27;[a-z]u&#x27;</span>)<span class="comment">#查看包含正则模式的序列</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ts.<span class="built_in">str</span>.startswith(<span class="string">&#x27;A&#x27;</span>)<span class="comment">#查看以A为开始的序列</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ts.<span class="built_in">str</span>.endswith(<span class="string">&#x27;e&#x27;</span>)<span class="comment">#查看以e为结尾的序列</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ts.<span class="built_in">str</span>.match(<span class="string">&#x27;A|s&#x27;</span>)<span class="comment">#查看以A为开头,s为结尾的序列</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ts.<span class="built_in">str</span>.count(<span class="string">&#x27;[A|s]&#x27;</span>)<span class="comment">#查看以A为开头,s为结尾的序列数量</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ts.<span class="built_in">str</span>.find(<span class="string">&#x27;de&#x27;</span>)<span class="comment">#从左往右寻找&#x27;de&#x27;,匹配返回位置索引,未找到返回&#x27;-1&#x27;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ts.<span class="built_in">str</span>.rfind(<span class="string">&#x27;de&#x27;</span>)<span class="comment">#从右往左寻找</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ts.<span class="built_in">str</span>.replace(<span class="string">&#x27;\s?&#x27;</span>, <span class="string">&#x27;LA&#x27;</span>, regex=<span class="literal">True</span>)<span class="comment">#使用正则进行字符串替换</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pat = <span class="string">&#x27;(\w+o)(\w+s)(\w+u)(\w+n)&#x27;</span></span><br><span class="line">ts.<span class="built_in">str</span>.extract(pat)<span class="comment">#拆分&#x27;o&#x27;,&#x27;s&#x27;,&#x27;u&#x27;,&#x27;n&#x27;为4列</span></span><br></pre></td></tr></table></figure>
<hr>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pd.to_numeric(ts, errors=<span class="string">&#x27;ignore&#x27;</span>)<span class="comment">#将可以转为数值的字符转为数值</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ts.<span class="built_in">str</span>.pad(<span class="number">6</span>,<span class="string">&#x27;left&#x27;</span>,<span class="string">&#x27;*&#x27;</span>)<span class="comment">#选定字符串长度为6的填充为&quot;*&quot;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ts.<span class="built_in">str</span>.lstrip()<span class="comment">#去掉字符串左侧空格</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ts.<span class="built_in">str</span>.zfill(<span class="number">8</span>)<span class="comment">#用0补足8位</span></span><br></pre></td></tr></table></figure>
<h4 id="3-分类数据"><a href="#3-分类数据" class="headerlink" title="3.分类数据"></a>3.分类数据</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s = df.psavert.astype(<span class="string">&#x27;category&#x27;</span>)<span class="comment">#Dataframe转为category对象</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s.cat.categories<span class="comment">#查看分类对象属性</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s.cat.add_categories(<span class="string">&#x27;C1&#x27;</span>)<span class="comment">#增加一个类别</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s.cat.remove_categories(<span class="number">11.7</span>)<span class="comment">#删除一个类别</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s = s.cat.rename_categories(&#123;<span class="string">&#x27;S1&#x27;</span>:<span class="string">&#x27;xxx&#x27;</span>&#125;)<span class="comment">#重命名类别及其值</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s.cat.reorder_categories([<span class="string">&#x27;S1&#x27;</span>, <span class="string">&#x27;S2&#x27;</span>, <span class="string">&#x27;S3&#x27;</span>, <span class="string">&#x27;S4&#x27;</span>], ordered=<span class="literal">True</span>)<span class="comment">#设置排序</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.sort_values(<span class="string">&#x27;psavert&#x27;</span>)<span class="comment">#值排序</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.set_index(<span class="string">&#x27;psavert&#x27;</span>).sort_index()<span class="comment">#作为索引排序</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">res = df.psavert &lt;= <span class="string">&#x27;S4&#x27;</span><span class="comment">#比较顺序</span></span><br><span class="line">res</span><br></pre></td></tr></table></figure>
<h4 id="4-时序数据"><a href="#4-时序数据" class="headerlink" title="4.时序数据"></a>4.时序数据</h4><p>————-图——————–</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s = pd.to_datetime(df.date)<span class="comment">#生成时间序列</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s2 = pd.to_datetime([<span class="string">&#x27;2020\\1\\1&#x27;</span>,<span class="string">&#x27;2020\\1\\3&#x27;</span>],<span class="built_in">format</span>=<span class="string">&#x27;%Y\\%m\\%d&#x27;</span>)<span class="comment">#强制格式转换,生成时间序列</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pd.date_range(<span class="string">&#x27;1967-07-01&#x27;</span>,<span class="string">&#x27;2015-04-01&#x27;</span>, freq=<span class="string">&#x27;D&#x27;</span>)<span class="comment">#查看两个时间之间的时间,间隔1天</span></span><br></pre></td></tr></table></figure>
<hr>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#dt对象</span></span><br><span class="line">s.dt.daysinmonth<span class="comment">#每个月几天</span></span><br><span class="line">s.dt.dayofweek<span class="comment">#每周几天</span></span><br><span class="line">s.dt.dayofweek.isin([<span class="number">5</span>,<span class="number">6</span>])<span class="comment">#是否包含双休日</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pd.Timestamp(<span class="string">&#x27;20210223 22:00:00&#x27;</span>)-pd.Timestamp(<span class="string">&#x27;20210222 18:35:00&#x27;</span>)<span class="comment">#计算两个时间之差</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Pandas</category>
      </categories>
      <tags>
        <tag>DataFrame</tag>
      </tags>
  </entry>
  <entry>
    <title>Tsfresh——自动化特征工程工具</title>
    <url>/2021/03/25/tsfresh/</url>
    <content><![CDATA[<blockquote>
<p>改进模型的潜在途径之一是：生成更多的潜在特征，输入更多的样本。</p>
</blockquote>
<p>Tsfresh是处理时间序列数据的特征工程工具，能够自动计算大量时间序列特征，如平均值、最大值、峰度等。之后，可以使用这些特征集构建机器学习模型。</p>
<p>本文以<em>天池-心跳信号分类预测</em>为例，演示tsfresh工具的用法。</p>
<h2 id="使用示例"><a href="#使用示例" class="headerlink" title="使用示例"></a>使用示例</h2><h5 id="1-合并train和test数据"><a href="#1-合并train和test数据" class="headerlink" title="1. 合并train和test数据"></a>1. 合并train和test数据</h5><p>合并数据集，对整体数据做统一的特征工程。(注意需要为test数据添加label列，值为-1，方便后续操作)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_test[<span class="string">&#x27;label&#x27;</span>] = -<span class="number">1</span></span><br><span class="line">all_data = pd.concat((data_train, data_test)).reset_index(drop = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<h5 id="2-对原特征一列拆成多列，并为每条数据添加时间特征time"><a href="#2-对原特征一列拆成多列，并为每条数据添加时间特征time" class="headerlink" title="2. 对原特征一列拆成多列，并为每条数据添加时间特征time"></a>2. 对原特征一列拆成多列，并为每条数据添加时间特征time</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">all_heatbeat_df = all_data[<span class="string">&#x27;heartbeat_signals&#x27;</span>].<span class="built_in">str</span>.split(<span class="string">&#x27;,&#x27;</span>, expand = <span class="literal">True</span>).stack()</span><br></pre></td></tr></table></figure>
<h5 id="3-Index处理"><a href="#3-Index处理" class="headerlink" title="3. Index处理"></a>3. Index处理</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">all_heatbeat_df = all_heatbeat_df.reset_inex()</span><br><span class="line">all_heatbeat_df = all_heatbeat_df.set_inex(<span class="string">&#x27;level_0&#x27;</span>)</span><br><span class="line">all_heatbeat_df.index.name = <span class="literal">None</span></span><br><span class="line">all_heatbeat_df.rename(columns=&#123;<span class="string">&#x27;level_1&#x27;</span>:<span class="string">&#x27;time&#x27;</span>, <span class="number">0</span>:<span class="string">&#x27;heartbeat_signals&#x27;</span>, inpalce = <span class="literal">True</span>&#125;)</span><br><span class="line">all_heatbeat_df[<span class="string">&#x27;heartbeat_signals&#x27;</span>].astype(<span class="built_in">float</span>)</span><br></pre></td></tr></table></figure>

<h5 id="4-label列单独存储，不进入tsfresh"><a href="#4-label列单独存储，不进入tsfresh" class="headerlink" title="4. label列单独存储，不进入tsfresh"></a>4. label列单独存储，不进入tsfresh</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">all_data_label = all_data[<span class="string">&#x27;label&#x27;</span>]</span><br><span class="line">all_data = all_data.drop[<span class="string">&#x27;label&#x27;</span>, axis=<span class="number">1</span>].drop[<span class="string">&#x27;heartbeat_signals&#x27;</span>, axis=<span class="number">1</span>]</span><br><span class="line">all_data = all_data.join(all_heatbeat_df)</span><br></pre></td></tr></table></figure>

<h5 id="5-tsfresh特征抽取"><a href="#5-tsfresh特征抽取" class="headerlink" title="5. tsfresh特征抽取"></a>5. tsfresh特征抽取</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> tsfresh <span class="keyword">import</span> extract_features</span><br><span class="line">all_features = extract_features(all_data, column_id=<span class="string">&#x27;id&#x27;</span>, column_sort=<span class="string">&#x27;time&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h5 id="6-特征选择"><a href="#6-特征选择" class="headerlink" title="6.特征选择"></a>6.特征选择</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#删除nan值</span></span><br><span class="line"><span class="keyword">from</span> tsfresh.utilities.dataframe_functions <span class="keyword">import</span> impute</span><br><span class="line">impute(all_features)</span><br></pre></td></tr></table></figure>

<h5 id="7-相关性特征提取"><a href="#7-相关性特征提取" class="headerlink" title="7.相关性特征提取"></a>7.相关性特征提取</h5><p>衍生众多特征之后，许多特征之间可能有很多相关性，需进一步筛选。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> tsfresh <span class="keyword">import</span> select_features</span><br><span class="line">all_features_filtered = select_features(all_features, all_data_label)</span><br></pre></td></tr></table></figure>
<h5 id="8-特征重命名，重新添加label"><a href="#8-特征重命名，重新添加label" class="headerlink" title="8.特征重命名，重新添加label"></a>8.特征重命名，重新添加label</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">num = all_features_filtered.columns.size</span><br><span class="line">all_features_filtered.columns = [<span class="string">&#x27;f_&#x27;</span> + <span class="built_in">str</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span> (<span class="number">0</span>, num)]</span><br><span class="line">all_features_filtered[<span class="string">&#x27;label&#x27;</span>] = all_data_label</span><br></pre></td></tr></table></figure>

<h4 id="tsfresh包深入探究"><a href="#tsfresh包深入探究" class="headerlink" title="tsfresh包深入探究"></a>tsfresh包深入探究</h4><h5 id="1-筛选特征的方法"><a href="#1-筛选特征的方法" class="headerlink" title="1. 筛选特征的方法"></a>1. 筛选特征的方法</h5><p>上文采用了手工打标签的方式划分训练集和测试集，略显麻烦，可以通过tsfresh的内置方法来提取训练数据。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">kind_to_fc_parameters = tsfresh.feature_extration.settings.from_columns(directed_features)</span><br></pre></td></tr></table></figure>
<p>生成的params为训练集的特征字典，可以当作参数传入后续计算中。</p>
<h5 id="2-自定义特征衍生规则"><a href="#2-自定义特征衍生规则" class="headerlink" title="2. 自定义特征衍生规则"></a>2. 自定义特征衍生规则</h5><p>tsfresh自带的衍生规则以字典的形式存放，可以直接调用，也可以自定义。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#单个特征计算</span></span><br><span class="line">tsfresh.feature_extraction.feature_calculators.abs_energy(x)</span><br><span class="line"></span><br><span class="line"><span class="comment">#设定衍生规则</span></span><br><span class="line"><span class="keyword">from</span> tsfresh.featureextraction <span class="keyword">import</span> extractfeatures</span><br><span class="line">params = &#123;<span class="string">&#x27;fft_coefficient:[&#123;&#x27;</span>coe<span class="string">f&#x27;:0, &#x27;</span>att<span class="string">r&#x27;:&#x27;</span><span class="built_in">abs</span><span class="string">&#x27;&#125;], &#x27;</span>kurtosis<span class="string">&#x27;: None, &#x27;</span>skewness<span class="string">&#x27;: None&#125;</span></span><br></pre></td></tr></table></figure>

<p>后续可以在extractfeatures中设置defaultparameters = params，具体用法见<a href="https://tsfresh.readthedocs.io/en/latest/text/feature_extraction_settings.html">操作文档</a>。</p>
<h5 id="3-减小内存使用"><a href="#3-减小内存使用" class="headerlink" title="3. 减小内存使用"></a>3. 减小内存使用</h5><p>tsfresh默认参数太吃内存，且耗时长，笔者i7的16G笔记本最多只能跑到60%的进度就会卡住，天池notebook和谷歌colab都是没跑出结果就断线了，硬要跑的话只能租个高配服务器，或者调整衍生特征的数量，通过<strong>chunksize</strong>设置，具体用法见<a href="https://tsfresh.readthedocs.io/en/latest/text/feature_extraction_settings.html">操作文档</a>。</p>
]]></content>
      <categories>
        <category>Feature engineering</category>
      </categories>
      <tags>
        <tag>tsfresh</tag>
      </tags>
  </entry>
  <entry>
    <title>地理数据分析常用工具</title>
    <url>/2021/04/15/%E5%9C%B0%E7%90%86%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/</url>
    <content><![CDATA[<p>在地理空间数据分析中，常用一些模块进行地理数据分析、特征提取及可视化，包括shapely、geopandas、folium、kepler.gl、geohash等工具。</p>
<h4 id="1-shapely"><a href="#1-shapely" class="headerlink" title="1. shapely"></a>1. shapely</h4><p>shapely是基于笛卡尔坐标的几何对象操作和分析Python库，底层基于GEOS和JTS拓扑运算库。</p>
<h5 id="1-1-Point对象"><a href="#1-1-Point对象" class="headerlink" title="1.1 Point对象"></a>1.1 Point对象</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> shapely.geometry <span class="keyword">import</span> Point</span><br><span class="line"></span><br><span class="line">point1 = Point(<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">point2 = Point(<span class="number">5</span>, <span class="number">5</span>)</span><br><span class="line">point3 = Point(<span class="number">10</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#点的可视化</span></span><br><span class="line">geo.GeometryCollection([point1,point2,point3])</span><br><span class="line"></span><br><span class="line"><span class="comment">#Point转为numpy数组</span></span><br><span class="line"><span class="built_in">print</span>(np.array(point))</span><br></pre></td></tr></table></figure>
<span id="more"></span>

<h5 id="1-2-LineString对象"><a href="#1-2-LineString对象" class="headerlink" title="1.2 LineString对象"></a>1.2 LineString对象</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建LineString对象</span></span><br><span class="line">line1 = geo.LineString([(<span class="number">0</span>,<span class="number">0</span>),(<span class="number">2</span>,-<span class="number">2.2</span>),(<span class="number">3</span>,<span class="number">3.3</span>),(<span class="number">4</span>,-<span class="number">4.4</span>),(<span class="number">5</span>,-<span class="number">5.5</span>),(<span class="number">6</span>,<span class="number">6.6</span>)])</span><br><span class="line">line1 </span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#点和线的可视化</span></span><br><span class="line">geo.GeometryCollection([line1,Point(<span class="number">1</span>,<span class="number">1</span>)])</span><br><span class="line"></span><br><span class="line"><span class="comment">#计算点线或线线的最短距离</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">&#x27;点线距离:&#x27;</span>+<span class="built_in">str</span>(Point(<span class="number">1</span>,<span class="number">1</span>).distance(line1)))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#几何中心</span></span><br><span class="line">center = line1.centroid </span><br><span class="line">geo.GeometryCollection([line1,center])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#几何对象的最小外接矩形</span></span><br><span class="line">b_rect = line1.envelope </span><br><span class="line">geo.GeometryCollection([line1,b_rect]) </span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"> <span class="comment">#简化线(Douglas-Pucker算法)</span></span><br><span class="line">line1_simplify = line1.simplify(<span class="number">0.4</span>, preserve_topology=<span class="literal">False</span>) </span><br><span class="line">line1</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#生成线的缓冲区</span></span><br><span class="line">buffer_with_circle = line1.buffer(<span class="number">0.3</span>)  </span><br><span class="line">geo.GeometryCollection([line1,buffer_with_circle])</span><br></pre></td></tr></table></figure>
<h5 id="1-3-LinearRings对象"><a href="#1-3-LinearRings对象" class="headerlink" title="1.3 LinearRings对象"></a>1.3 LinearRings对象</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> shapely.geometry.polygon <span class="keyword">import</span> LinearRing</span><br><span class="line"></span><br><span class="line">ring = geo.polygon.LinearRing([(<span class="number">0</span>, <span class="number">0</span>), (<span class="number">1</span>, -<span class="number">1</span>), (<span class="number">1</span>, <span class="number">0</span>)])</span><br><span class="line">geo.GeometryCollection([ring])</span><br></pre></td></tr></table></figure>

<h5 id="1-4-Polygon对象"><a href="#1-4-Polygon对象" class="headerlink" title="1.4 Polygon对象"></a>1.4 Polygon对象</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> shapely.geometry <span class="keyword">import</span> Polygon</span><br><span class="line"></span><br><span class="line">poly1 = Polygon([(<span class="number">0</span>,<span class="number">0</span>),(<span class="number">2</span>,<span class="number">0</span>),(<span class="number">1</span>,-<span class="number">1</span>),(-<span class="number">3</span>,<span class="number">1</span>),(<span class="number">0</span>,<span class="number">0</span>)]) <span class="comment">#起点和终点相同</span></span><br><span class="line">poly1</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#通过numpy生成多边形</span></span><br><span class="line">coords = np.array([(<span class="number">0</span>,<span class="number">0</span>),(<span class="number">1</span>,<span class="number">0.1</span>),(<span class="number">2</span>,<span class="number">0</span>),(<span class="number">1</span>,<span class="number">2</span>),(<span class="number">0</span>,<span class="number">0</span>)])</span><br><span class="line">poly2 = Polygon(coords)</span><br><span class="line">poly2 </span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#多个polygon的集合</span></span><br><span class="line">geo.GeometryCollection([poly1,poly2])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#几何中心</span></span><br><span class="line">center = poly1.centroid <span class="comment">#几何中心</span></span><br><span class="line">geo.GeometryCollection([center,poly1]) </span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#最小外接矩形</span></span><br><span class="line">rect = poly1.minimum_rotated_rectangle <span class="comment">#最小外接矩形</span></span><br><span class="line">geo.GeometryCollection([rect,poly1])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">poly1.boundary<span class="comment">#边缘</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">poly2.simplify(<span class="number">0.5</span>)<span class="comment">#简化面</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">r1 = poly2.contains(point2) <span class="comment">#面点关系</span></span><br><span class="line"><span class="built_in">print</span>(r1)</span><br><span class="line"></span><br><span class="line">r2 = poly2.intersects(line1) <span class="comment">#面线关系</span></span><br><span class="line"><span class="built_in">print</span>(r2)</span><br><span class="line"></span><br><span class="line">r3 = poly1.intersects(poly2) <span class="comment">#面面关系</span></span><br><span class="line"><span class="built_in">print</span>(r3)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">poly1.intersection(poly2) <span class="comment">#面面交集</span></span><br><span class="line">poly1.union(poly2) 		  <span class="comment">#面面并集</span></span><br><span class="line">poly2.difference(poly1)   <span class="comment">#面面补集</span></span><br></pre></td></tr></table></figure>
<h4 id="2-geopandas"><a href="#2-geopandas" class="headerlink" title="2. geopandas"></a>2. geopandas</h4><p>geopandas是pandas在地理数据处理领域的扩展包，其核心数据结构是GeoSeries和GeoDataFrame。<br>geopandasd 主要功能为:</p>
<blockquote>
<p>1.文件读写<br>2.空间查询<br>3.坐标转换<br>4.空间join<br>5.地理数据可视化</p>
</blockquote>
<h5 id="2-1-文件读写"><a href="#2-1-文件读写" class="headerlink" title="2.1 文件读写"></a>2.1 文件读写</h5><p>geopandas可读geojson和shp等空间文件，也可读含有geometry字段的csv文件。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="keyword">import</span> shapely </span><br><span class="line"><span class="keyword">import</span> geopandas <span class="keyword">as</span> gpd </span><br><span class="line"><span class="keyword">from</span> shapely <span class="keyword">import</span> wkt </span><br><span class="line"><span class="keyword">from</span> shapely <span class="keyword">import</span> geometry <span class="keyword">as</span> geo</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#读取geojson</span></span><br><span class="line">countries = gpd.read_file(<span class="string">&quot;dfcountries.geojson&quot;</span>,bbox = [-<span class="number">180</span>,-<span class="number">80</span>,<span class="number">180</span>,<span class="number">80</span>])</span><br><span class="line">countries.plot()<span class="comment">#显示图</span></span><br><span class="line">countries		<span class="comment">#显示表格</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#读取shp</span></span><br><span class="line">cities = gpd.GeoDataFrame.from_file(<span class="string">&#x27;./cities.shp&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">cities.plot()<span class="comment">#显示图</span></span><br><span class="line">cities		 <span class="comment">#显示表格</span></span><br></pre></td></tr></table></figure>
<p><img src="https://ae01.alicdn.com/kf/U1e0d77ed2da2455cb9957e8ed6f59c20a.jpg" alt="f1"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#保存成geojson</span></span><br><span class="line">countries.to_file(<span class="string">&quot;dfcountries.geojson&quot;</span>,driver = <span class="string">&quot;GeoJSON&quot;</span>)</span><br><span class="line"><span class="comment">#保存成csv</span></span><br><span class="line">cities.to_csv(<span class="string">&quot;dfcountries.csv&quot;</span>,index = <span class="literal">False</span>,sep = <span class="string">&quot;\t&quot;</span>)</span><br><span class="line"><span class="comment">#保存成shp</span></span><br><span class="line">cities.to_file(<span class="string">&quot;.a/cities.shp&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#按值的大小填充颜色</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">9</span>,<span class="number">6</span>),dpi = <span class="number">100</span>)</span><br><span class="line">cities.plot(<span class="string">&#x27;area&#x27;</span>,ax = ax,legend = <span class="literal">True</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://ae01.alicdn.com/kf/U31c06924a773420bb62cc56d2ee9442ft.jpg" alt="f2"></p>
<h4 id="3-Folium"><a href="#3-Folium" class="headerlink" title="3.Folium"></a>3.Folium</h4><p>folium是一种交互式动态地图接口，可以用来画热力图、填充地图、路径图、散点标记等图。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> folium</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment">#指定坐标中心和缩放尺寸，生成交互式地图</span></span><br><span class="line">m = folium.Map(location=[<span class="number">30.33</span>,<span class="number">120.37</span>],zoom_start=<span class="number">10</span>)</span><br><span class="line">m</span><br></pre></td></tr></table></figure>
<p><img src="https://ae01.alicdn.com/kf/Uc6be8164498d4fda99801e6d30ac676eV.jpg" alt="f3"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> folium.plugins <span class="keyword">import</span> HeatMap</span><br><span class="line"><span class="comment">#生成随机数据，指定坐标中心和缩放尺寸，生成热力图</span></span><br><span class="line">data=(np.random.normal(size=(<span class="number">100</span>,<span class="number">3</span>))*np.array([[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>]])+np.array([[<span class="number">30.33</span>,<span class="number">120.37</span>,<span class="number">1</span>]])).tolist()</span><br><span class="line">m=folium.Map([<span class="number">30.33</span>,<span class="number">120.37</span>],tiles=<span class="string">&#x27;Stamen Toner&#x27;</span>,zoom_start=<span class="number">6</span>)</span><br><span class="line">HeatMap(data).add_to(m)</span><br><span class="line">m </span><br></pre></td></tr></table></figure>
<p><img src="https://ae01.alicdn.com/kf/U1fe179343a464ab1926cd10582207986X.jpg" alt="f4"></p>
<p>folium的MarkerCluster()聚类函数，可以用来反映一个区域的拥挤程度。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> folium.plugins <span class="keyword">import</span> MarkerCluster</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建对象</span></span><br><span class="line">marker_cluster = MarkerCluster().add_to(m)</span><br><span class="line"></span><br><span class="line"><span class="comment">#将经纬度加入聚类</span></span><br><span class="line"><span class="keyword">for</span> element <span class="keyword">in</span> data:</span><br><span class="line">    folium.Marker(location=[element[<span class="number">0</span>], element[<span class="number">1</span>]],icon=<span class="literal">None</span>).add_to(marker_cluster)</span><br><span class="line"></span><br><span class="line"><span class="comment">#添加至地图</span></span><br><span class="line">m.add_child(marker_cluster)</span><br><span class="line">m</span><br></pre></td></tr></table></figure>

<h4 id="4-Kepler-gl"><a href="#4-Kepler-gl" class="headerlink" title="4.Kepler.gl"></a>4.Kepler.gl</h4><p>Kepler.gl是Uber联合Mapbox推出的地理空间可视化工具，支持3种数据格式：CSV、JSON、GeoJSON。接下来将以杭州市OSM路网为例，制作路径流动动画。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keplergl <span class="keyword">import</span> KeplerGl</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> time</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#读取geojson</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./hzroad.json&#x27;</span>,encoding=<span class="string">&#x27;gb18030&#x27;</span>, errors=<span class="string">&#x27;ignore&#x27;</span>) <span class="keyword">as</span> g:</span><br><span class="line">    raw_roads = json.load(g)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#生成虚构时间戳信息和高度0</span></span><br><span class="line">start_time = time.mktime(time.strptime(<span class="string">&#x27;2020-05-29 20:00:00&#x27;</span>, <span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(raw_roads[<span class="string">&#x27;features&#x27;</span>].__len__()):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(raw_roads[<span class="string">&#x27;features&#x27;</span>][i][<span class="string">&#x27;geometry&#x27;</span>][<span class="string">&#x27;coordinates&#x27;</span>].__len__()):</span><br><span class="line">        <span class="comment"># 更新当前对应的时间戳</span></span><br><span class="line">        shift_time = <span class="built_in">int</span>((j / raw_roads[<span class="string">&#x27;features&#x27;</span>][i][<span class="string">&#x27;geometry&#x27;</span>][<span class="string">&#x27;coordinates&#x27;</span>].__len__())*<span class="number">3600</span>) </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 高度设置为0</span></span><br><span class="line">        raw_roads[<span class="string">&#x27;features&#x27;</span>][i][<span class="string">&#x27;geometry&#x27;</span>][<span class="string">&#x27;coordinates&#x27;</span>][j] \</span><br><span class="line">            .extend([<span class="number">0</span>, </span><br><span class="line">                     <span class="built_in">int</span>(start_time) + shift_time])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keplergl <span class="keyword">import</span> KeplerGl</span><br><span class="line"><span class="comment"># 生成KeplerGl对象</span></span><br><span class="line">m = KeplerGl(height=<span class="number">400</span>, </span><br><span class="line">                data=&#123;<span class="string">&#x27;flow&#x27;</span>: raw_roads&#125;) <span class="comment"># data以图层名为键，对应的矢量数据为值</span></span><br><span class="line">m</span><br><span class="line">m.save_to_html(file_name=<span class="string">&#x27;./hangzhou.html&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h4 id="5-Geohash"><a href="#5-Geohash" class="headerlink" title="5.Geohash"></a>5.Geohash</h4><p>GeoHash是一种地址编码方法，可以将地理经纬度坐标编码为由字母和数字所构成的字符串。其原理类似哈希表：由于遍历列表查找时间复杂度高，而创建散列函数能够更高效地定位数据。而GeoHash将二维的经纬度坐标编码到一维的字符串中，在做地理位置索引时只需匹配字符串，便于信息的缓存和压缩。</p>
<p>GeoHash采用二分法不断缩小经度和纬度的区间来进行二进制编码，最后将经纬度分别产生的编码奇偶位交叉合并，再用字母数字表示。</p>
<p><img src="https://ae01.alicdn.com/kf/Uf288553e6d2c43038976764613dd1cc1x.jpg" alt="f6"></p>
<blockquote>
<p>p.s. 酷炫动图见公众号</p>
</blockquote>
]]></content>
      <categories>
        <category>geospatial data analysis</category>
        <category>data visualization</category>
        <category>GIS</category>
      </categories>
      <tags>
        <tag>geopandas</tag>
        <tag>shapely</tag>
        <tag>Kepler.gl</tag>
        <tag>folium</tag>
        <tag>geohash</tag>
      </tags>
  </entry>
  <entry>
    <title>特征工程_1</title>
    <url>/2021/04/21/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B_1/</url>
    <content><![CDATA[<p>特征工程就是将原始数据空间变换到新的特征空间，在新的特征空间中，模型能够更好地学习数据中的规律。特征的选择和构造，就是人为地帮助模型学习到原本很难学好的东西，从而使模型达到更好的效果。</p>
<h4 id="1-根据现实情况构造特征"><a href="#1-根据现实情况构造特征" class="headerlink" title="1. 根据现实情况构造特征"></a>1. 根据现实情况构造特征</h4><h5 id="1-1-各点与特定点的距离"><a href="#1-1-各点与特定点的距离" class="headerlink" title="1.1 各点与特定点的距离"></a>1.1 各点与特定点的距离</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[<span class="string">&#x27;x_dis&#x27;</span>] = (df[<span class="string">&#x27;x&#x27;</span>] - <span class="number">6165599</span>).<span class="built_in">abs</span>()</span><br><span class="line">df[<span class="string">&#x27;y_dis&#x27;</span>] = (df[<span class="string">&#x27;y&#x27;</span>] - <span class="number">5202660</span>).<span class="built_in">abs</span>()</span><br><span class="line">df[<span class="string">&#x27;base_dis] = (df[&#x27;</span>y_dis<span class="string">&#x27;]**2))**0.5 + ((df[&#x27;</span>x_dis<span class="string">&#x27;]**2)</span></span><br><span class="line"><span class="string">del df[&#x27;</span>x_dis<span class="string">&#x27;],df[&#x27;</span>y_dis<span class="string">&#x27;] </span></span><br><span class="line"><span class="string">df[&#x27;</span>base_dis_dif<span class="string">f&#x27;].head()</span></span><br></pre></td></tr></table></figure>
<h5 id="1-2-将时间划分为白天与黑夜"><a href="#1-2-将时间划分为白天与黑夜" class="headerlink" title="1.2 将时间划分为白天与黑夜"></a>1.2 将时间划分为白天与黑夜</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[<span class="string">&#x27;day_night&#x27;</span>] = <span class="number">0</span></span><br><span class="line">df.loc[(df[<span class="string">&#x27;hour&#x27;</span>] &gt; <span class="number">5</span>) &amp; (df[<span class="string">&#x27;hour&#x27;</span>] &lt; <span class="number">20</span>),<span class="string">&#x27;day_night&#x27;</span>] = <span class="number">1</span></span><br><span class="line">df[<span class="string">&#x27;day_night&#x27;</span>].head()</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<h5 id="1-3-将月份划分为季度"><a href="#1-3-将月份划分为季度" class="headerlink" title="1.3 将月份划分为季度"></a>1.3 将月份划分为季度</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[<span class="string">&#x27;quarter&#x27;</span>] = <span class="number">0</span></span><br><span class="line">df.loc[(df[<span class="string">&#x27;month&#x27;</span>].isin([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])), <span class="string">&#x27;quarter&#x27;</span>] = <span class="number">1</span></span><br><span class="line">df.loc[(df[<span class="string">&#x27;month&#x27;</span>].isin([<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, ])), <span class="string">&#x27;quarter&#x27;</span>] = <span class="number">2</span></span><br><span class="line">df.loc[(df[<span class="string">&#x27;month&#x27;</span>].isin([<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])), <span class="string">&#x27;quarter&#x27;</span>] = <span class="number">3</span></span><br><span class="line">df.loc[(df[<span class="string">&#x27;month&#x27;</span>].isin([<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>])), <span class="string">&#x27;quarter&#x27;</span>] = <span class="number">4</span></span><br></pre></td></tr></table></figure>
<h5 id="1-4-特征变化量之间的相似性"><a href="#1-4-特征变化量之间的相似性" class="headerlink" title="1.4 特征变化量之间的相似性"></a>1.4 特征变化量之间的相似性</h5><p>①统计每个ship的对应速度等级的个数.<br>②对方位进行16均分.<br>③统计速度为0的个数，以及速度不为0的统计量.<br>④加入x，v，d，y的中位数和各种位数,并删去count\mean\min\max\std等多余统计特征.<br>⑤以shift为主键,求相邻差异值(偏移量).</p>
<h4 id="2-构造分箱特征"><a href="#2-构造分箱特征" class="headerlink" title="2. 构造分箱特征"></a>2. 构造分箱特征</h4><h5 id="2-1-经纬度和速度的分箱特征"><a href="#2-1-经纬度和速度的分箱特征" class="headerlink" title="2.1 经纬度和速度的分箱特征"></a>2.1 经纬度和速度的分箱特征</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[<span class="string">&#x27;v_bin&#x27;</span>] = pd.qcut(df[<span class="string">&#x27;v&#x27;</span>], <span class="number">200</span>, duplicates=<span class="string">&#x27;drop&#x27;</span>) <span class="comment"># 速度进行 200分位数分箱</span></span><br><span class="line">df[<span class="string">&#x27;v_bin&#x27;</span>] = df[<span class="string">&#x27;v_bin&#x27;</span>].<span class="built_in">map</span>(<span class="built_in">dict</span>(<span class="built_in">zip</span>(df[<span class="string">&#x27;v_bin&#x27;</span>].unique().<span class="built_in">range</span>(df[<span class="string">&#x27;v_bin&#x27;</span>].nunique())))) <span class="comment"># 分箱后映射编码</span></span><br></pre></td></tr></table></figure>

<h5 id="2-2-经纬度分箱后并构造区域"><a href="#2-2-经纬度分箱后并构造区域" class="headerlink" title="2.2 经纬度分箱后并构造区域"></a>2.2 经纬度分箱后并构造区域</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">traj.sort_values(by=<span class="string">&#x27;x&#x27;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">x_res = np.zeros((<span class="built_in">len</span>(traj), ))</span><br><span class="line">j = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, col_bins + <span class="number">1</span>):</span><br><span class="line">    low, high = x_bins[i-<span class="number">1</span>], x_bins[i]</span><br><span class="line">    <span class="keyword">while</span>( j &lt; <span class="built_in">len</span>(traj)):</span><br><span class="line">        <span class="keyword">if</span> (traj[<span class="string">&quot;x&quot;</span>].iloc[j] &lt;= high) &amp; (traj[<span class="string">&quot;x&quot;</span>].iloc[j] &gt; low - <span class="number">0.001</span>):</span><br><span class="line">            x_res[j] = i</span><br><span class="line">            j += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure>

<h4 id="3-构造DataFramte特征"><a href="#3-构造DataFramte特征" class="headerlink" title="3. 构造DataFramte特征"></a>3. 构造DataFramte特征</h4><h5 id="3-1-count计数值"><a href="#3-1-count计数值" class="headerlink" title="3.1 count计数值"></a>3.1 count计数值</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_save_unique_visit_count_table</span>(<span class="params">traj_data_df=<span class="literal">None</span>, bin_to_coord_df=<span class="literal">None</span></span>):</span></span><br><span class="line">    unique_boat_count_df = traj_data_df.groupby([<span class="string">&quot;no_bin&quot;</span>])[<span class="string">&quot;id&quot;</span>].nunique().reset_index()</span><br><span class="line">    unique_boat_count_df.rename(&#123;<span class="string">&quot;id&quot;</span>:<span class="string">&quot;visit_boat_count&quot;</span>&#125;, axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    unique_boat_count_df_save = pd.merge(bin_to_coord_df, unique_boat_count_df,</span><br><span class="line">                                         on=<span class="string">&quot;no_bin&quot;</span>, how=<span class="string">&quot;left&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> unique_boat_count_d</span><br></pre></td></tr></table></figure>
<h5 id="3-2-shift偏移量"><a href="#3-2-shift偏移量" class="headerlink" title="3.2 shift偏移量"></a>3.2 shift偏移量</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> f <span class="keyword">in</span> [<span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;y&#x27;</span>]:</span><br><span class="line">    <span class="comment">#对x,y坐标进行时间平移 1 -1 2</span></span><br><span class="line">    df[f + <span class="string">&#x27;_prev_diff&#x27;</span>] = df[f] - g[f].shift(<span class="number">1</span>)</span><br><span class="line">    df[f + <span class="string">&#x27;_next_diff&#x27;</span>] = df[f] - g[f].shift(-<span class="number">1</span>)</span><br><span class="line">    df[f + <span class="string">&#x27;_prev_next_diff&#x27;</span>] = g[f].shift(<span class="number">1</span>) - g[f].shift(-<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h5 id="3-3-统计特征"><a href="#3-3-统计特征" class="headerlink" title="3.3 统计特征"></a>3.3 统计特征</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">group_feature</span>(<span class="params">df, key, target, aggs,flag</span>):</span>   </span><br><span class="line">    <span class="comment">#通过字典的形式来构建方法和重命名</span></span><br><span class="line">    agg_dict = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> ag <span class="keyword">in</span> aggs:</span><br><span class="line">        agg_dict[<span class="string">&#x27;&#123;&#125;_&#123;&#125;_&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(target,ag,flag)] = ag</span><br><span class="line">        </span><br><span class="line">    t = df.groupby(key)[target].agg(agg_dict).reset_index()</span><br><span class="line">    <span class="keyword">return</span> t</span><br><span class="line"></span><br><span class="line">t = group_feature(df, <span class="string">&#x27;ship&#x27;</span>,<span class="string">&#x27;x&#x27;</span>,[<span class="string">&#x27;max&#x27;</span>,<span class="string">&#x27;min&#x27;</span>,<span class="string">&#x27;mean&#x27;</span>,<span class="string">&#x27;median&#x27;</span>,<span class="string">&#x27;std&#x27;</span>,<span class="string">&#x27;skew&#x27;</span>],flag)</span><br><span class="line">train = pd.merge(train, t, on=<span class="string">&#x27;ship&#x27;</span>, how=<span class="string">&#x27;left&#x27;</span>)</span><br><span class="line">t = group_feature(df, <span class="string">&#x27;ship&#x27;</span>,<span class="string">&#x27;y&#x27;</span>,[<span class="string">&#x27;max&#x27;</span>,<span class="string">&#x27;min&#x27;</span>,<span class="string">&#x27;mean&#x27;</span>,<span class="string">&#x27;median&#x27;</span>,<span class="string">&#x27;std&#x27;</span>,<span class="string">&#x27;skew&#x27;</span>],flag)</span><br><span class="line">train = pd.merge(train, t, on=<span class="string">&#x27;ship&#x27;</span>, how=<span class="string">&#x27;left&#x27;</span>)</span><br><span class="line">t = group_feature(df, <span class="string">&#x27;ship&#x27;</span>,<span class="string">&#x27;base_dis_diff&#x27;</span>,[<span class="string">&#x27;max&#x27;</span>,<span class="string">&#x27;min&#x27;</span>,<span class="string">&#x27;mean&#x27;</span>,<span class="string">&#x27;std&#x27;</span>,<span class="string">&#x27;skew&#x27;</span>],flag)</span><br><span class="line">train = pd.merge(train, t, on=<span class="string">&#x27;ship&#x27;</span>, how=<span class="string">&#x27;left&#x27;</span>)</span><br></pre></td></tr></table></figure>


<h4 id="4-构造Embedding特征"><a href="#4-构造Embedding特征" class="headerlink" title="4.构造Embedding特征"></a>4.构造Embedding特征</h4><p>word embedding就是将词映射到另外一个空间,相同类型的词在投影之后的向量空间距离更近,倾向于归到一起.</p>
<h5 id="4-1-Word2vec构造词向量"><a href="#4-1-Word2vec构造词向量" class="headerlink" title="4.1 Word2vec构造词向量"></a>4.1 Word2vec构造词向量</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(num_runs)):</span><br><span class="line">    model = Word2Vec(sentences, size=embedding_size,</span><br><span class="line">                              min_count=min_count,</span><br><span class="line">                              workers=mp.cpu_count(),</span><br><span class="line">                              window=window_size,</span><br><span class="line">                              seed=seed, <span class="built_in">iter</span>=iters, sg=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    embedding_vec = []</span><br><span class="line">    <span class="keyword">for</span> ind, seq <span class="keyword">in</span> <span class="built_in">enumerate</span>(sentences):</span><br><span class="line">        seq_vec, word_count = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> seq:</span><br><span class="line">            <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> model:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                seq_vec += model[word]</span><br><span class="line">                word_count += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> word_count == <span class="number">0</span>:</span><br><span class="line">            embedding_vec.append(embedding_size * [<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            embedding_vec.append(seq_vec / word_count)</span><br></pre></td></tr></table></figure>

<h5 id="4-2-NMF提取文本的主题分布"><a href="#4-2-NMF提取文本的主题分布" class="headerlink" title="4.2 NMF提取文本的主题分布"></a>4.2 NMF提取文本的主题分布</h5><p>TF-IDF是衡量字词的出现频率来定义其重要性的加权技术.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用tfidf对元素进行处理</span></span><br><span class="line">tfidf_vectorizer = TfidfVectorizer(ngram_range=(tf_n,tf_n))</span><br><span class="line">tfidf = tfidf_vectorizer.fit_transform(self.data[<span class="string">&#x27;title_feature&#x27;</span>].values)</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用nmf算法，提取文本的主题分布</span></span><br><span class="line">text_nmf = NMF(n_components=self.nmf_n).fit_transform(tfidf)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Feature engineering</category>
        <category>Pandas</category>
      </categories>
      <tags>
        <tag>Embedding</tag>
        <tag>Word2vec</tag>
        <tag>NMF</tag>
        <tag>DataFramte</tag>
      </tags>
  </entry>
  <entry>
    <title>模型融合_1</title>
    <url>/2021/03/15/%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88_1/</url>
    <content><![CDATA[<p>Kaggle和天池比赛中常用提高成绩的三种方法：</p>
<blockquote>
<p>1.特征工程<br>2.模型调参<br>3.模型融合<br>模型融合主要有以下几种方式：</p>
</blockquote>
<h4 id="简单加权融合"><a href="#简单加权融合" class="headerlink" title="简单加权融合:"></a>简单加权融合:</h4><blockquote>
<p>①回归（分类概率）：算术平均融合（Arithmetic mean），几何平均融合（Geometric mean）；<br>②分类：投票（Voting)<br>③综合：排序融合(Rank averaging)，log融合</p>
</blockquote>
<h4 id="stacking-blending"><a href="#stacking-blending" class="headerlink" title="stacking/blending:"></a>stacking/blending:</h4><blockquote>
<p>构建多层模型，把初级学习器的输出当作下一层的输入。</p>
</blockquote>
<span id="more"></span>
<h4 id="boosting-bagging（在xgboost-Adaboost-GBDT中已经用到）"><a href="#boosting-bagging（在xgboost-Adaboost-GBDT中已经用到）" class="headerlink" title="boosting/bagging（在xgboost,Adaboost,GBDT中已经用到）:"></a>boosting/bagging（在xgboost,Adaboost,GBDT中已经用到）:</h4><blockquote>
<p>多个分类器的整合</p>
</blockquote>
<h4 id="部分代码案例"><a href="#部分代码案例" class="headerlink" title="部分代码案例:"></a>部分代码案例:</h4><h5 id="1-简单加权平均"><a href="#1-简单加权平均" class="headerlink" title="1.简单加权平均"></a>1.简单加权平均</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Weighted_method</span>(<span class="params">test_pre1,test_pre2,test_pre3,w=[<span class="number">1</span>/<span class="number">3</span>,<span class="number">1</span>/<span class="number">3</span>,<span class="number">1</span>/<span class="number">3</span>]</span>):</span></span><br><span class="line">    Weighted_result = w[<span class="number">0</span>]*pd.Series(test_pre1)+w[<span class="number">1</span>]*pd.Series(test_pre2)+w[<span class="number">2</span>]*pd.Series(test_pre3)</span><br><span class="line">    <span class="keyword">return</span> Weighted_result</span><br><span class="line">    </span><br><span class="line">Weighted_pre = Weighted_method(test_pre1,test_pre2,test_pre3,w)</span><br></pre></td></tr></table></figure>
<h5 id="2-Stacking融合-回归"><a href="#2-Stacking融合-回归" class="headerlink" title="2.Stacking融合(回归)"></a>2.Stacking融合(回归)</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Stacking_method</span>(<span class="params">train_reg1,train_reg2,train_reg3,y_train_true,test_pre1,test_pre2,test_pre3,model_L2= linear_model.LinearRegression(<span class="params"></span>)</span>):</span>    model_L2.fit(pd.concat([pd.Series(train_reg1),pd.Series(train_reg2),pd.Series(train_reg3)],axis=<span class="number">1</span>).values,y_train_true)</span><br><span class="line">    Stacking_result = model_L2.predict(pd.concat([pd.Series(test_pre1),pd.Series(test_pre2),pd.Series(test_pre3)],axis=<span class="number">1</span>).values)</span><br><span class="line">    <span class="keyword">return</span> Stacking_result</span><br><span class="line"></span><br><span class="line">Stacking_pre = Stacking_method(train_reg1,train_reg2,train_reg3,y_train_true,</span><br><span class="line">                               test_pre1,test_pre2,test_pre3,model_L2)</span><br></pre></td></tr></table></figure>
<h5 id="3-Voting投票机制"><a href="#3-Voting投票机制" class="headerlink" title="3.Voting投票机制"></a>3.Voting投票机制</h5><blockquote>
<p>硬投票：对多个模型直接进行投票，不区分模型结果的相对重要度，最终投票数最多的类为最终被预测的类。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">eclf = VotingClassifier(estimators=[(<span class="string">&#x27;lgb&#x27;</span>, clf1), (<span class="string">&#x27;rf&#x27;</span>, clf2), (<span class="string">&#x27;svc&#x27;</span>, clf3)], voting=<span class="string">&#x27;hard&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> clf, label <span class="keyword">in</span> <span class="built_in">zip</span>([clf1, clf2, clf3, eclf], [<span class="string">&#x27;LGB&#x27;</span>, <span class="string">&#x27;Random Forest&#x27;</span>, <span class="string">&#x27;SVM&#x27;</span>, <span class="string">&#x27;Ensemble&#x27;</span>]):</span><br><span class="line">    scores = cross_val_score(clf, x, y, cv=<span class="number">5</span>, scoring=<span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Accuracy: %0.2f (+/- %0.2f) [%s]&quot;</span> % (scores.mean(), scores.std(), label))</span><br></pre></td></tr></table></figure>
<h5 id="4-分类模型的Stacking融合"><a href="#4-分类模型的Stacking融合" class="headerlink" title="4.分类模型的Stacking融合"></a>4.分类模型的Stacking融合</h5><blockquote>
<p>Stacking与Blending相比存在一定优势:<br>1.充分使用数据<br>2.使用多次的交叉验证会比较稳健<br>3.不容易过拟合</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">clfs = [LogisticRegression(solver=<span class="string">&#x27;lbfgs&#x27;</span>),</span><br><span class="line">        RandomForestClassifier(n_estimators=<span class="number">5</span>, n_jobs=-<span class="number">1</span>, criterion=<span class="string">&#x27;gini&#x27;</span>),</span><br><span class="line">        RandomForestClassifier(n_estimators=<span class="number">5</span>, n_jobs=-<span class="number">1</span>, criterion=<span class="string">&#x27;entropy&#x27;</span>),</span><br><span class="line">        ExtraTreesClassifier(n_estimators=<span class="number">5</span>, n_jobs=-<span class="number">1</span>, criterion=<span class="string">&#x27;gini&#x27;</span>),</span><br><span class="line">        GradientBoostingClassifier(learning_rate=<span class="number">0.05</span>, subsample=<span class="number">0.5</span>, max_depth=<span class="number">6</span>, n_estimators=<span class="number">5</span>)]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> j, clf <span class="keyword">in</span> <span class="built_in">enumerate</span>(clfs):</span><br><span class="line">    <span class="comment">#依次训练各个单模型</span></span><br><span class="line">    clf.fit(X_d1, y_d1)</span><br><span class="line">    y_submission = clf.predict_proba(X_d2)[:, <span class="number">1</span>]</span><br><span class="line">    dataset_d1[:, j] = y_submission</span><br><span class="line">    <span class="comment">#对于测试集，直接用这k个模型的预测值作为新的特征。</span></span><br><span class="line">    dataset_d2[:, j] = clf.predict_proba(X_predict)[:, <span class="number">1</span>]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;val auc Score: %f&quot;</span> % roc_auc_score(y_predict, dataset_d2[:, j]))</span><br><span class="line"></span><br><span class="line"><span class="comment">#融合使用的模型</span></span><br><span class="line">clf = GradientBoostingClassifier(learning_rate=<span class="number">0.02</span>, subsample=<span class="number">0.5</span>, max_depth=<span class="number">6</span>, n_estimators=<span class="number">30</span>)</span><br><span class="line">clf.fit(dataset_d1, y_d2)</span><br></pre></td></tr></table></figure>
<h5 id="5-其他Stacking"><a href="#5-其他Stacking" class="headerlink" title="5.其他Stacking"></a>5.其他Stacking</h5><blockquote>
<p>将特征放进模型中预测，并将预测结果变换并作为新的特征加入原有特征中再经过模型预测结果</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Ensemble_add_feature</span>(<span class="params">train,test,target,clfs</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> j,clf <span class="keyword">in</span> <span class="built_in">enumerate</span>(clfs):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;依次训练各个单模型&#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># print(j, clf)</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;使用第1个部分作为预测，第2部分来训练模型，获得其预测的输出作为第2部分的新特征。&#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># X_train, y_train, X_test, y_test = X[train], y[train], X[test], y[test]</span></span><br><span class="line"></span><br><span class="line">        clf.fit(train,target)</span><br><span class="line">        y_train = clf.predict(train)</span><br><span class="line">        y_test = clf.predict(test)</span><br><span class="line"></span><br><span class="line">        <span class="comment">## 新特征生成</span></span><br><span class="line">        train_[:,j*<span class="number">2</span>] = y_train**<span class="number">2</span></span><br><span class="line">        test_[:,j*<span class="number">2</span>] = y_test**<span class="number">2</span></span><br><span class="line">        train_[:, j+<span class="number">1</span>] = np.exp(y_train)</span><br><span class="line">        test_[:, j+<span class="number">1</span>] = np.exp(y_test)</span><br><span class="line">        <span class="comment"># print(&quot;val auc Score: %f&quot; % r2_score(y_predict, dataset_d2[:, j]))</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Method &#x27;</span>,j)</span><br><span class="line"></span><br><span class="line">    train_ = pd.DataFrame(train_)</span><br><span class="line">    test_ = pd.DataFrame(test_)</span><br><span class="line">    <span class="keyword">return</span> train_,test_</span><br><span class="line"></span><br><span class="line"><span class="comment">#模型融合中使用到的各个单模型</span></span><br><span class="line">clfs = [LogisticRegression(),</span><br><span class="line">        RandomForestClassifier(n_estimators=<span class="number">5</span>, n_jobs=-<span class="number">1</span>, criterion=<span class="string">&#x27;gini&#x27;</span>),</span><br><span class="line">        ExtraTreesClassifier(n_estimators=<span class="number">5</span>, n_jobs=-<span class="number">1</span>, criterion=<span class="string">&#x27;gini&#x27;</span>),</span><br><span class="line">        ExtraTreesClassifier(n_estimators=<span class="number">5</span>, n_jobs=-<span class="number">1</span>, criterion=<span class="string">&#x27;entropy&#x27;</span>),</span><br><span class="line">        GradientBoostingClassifier(learning_rate=<span class="number">0.05</span>, subsample=<span class="number">0.5</span>, max_depth=<span class="number">6</span>, n_estimators=<span class="number">5</span>)]</span><br><span class="line"></span><br><span class="line">New_train,New_test = Ensemble_add_feature(x_train,x_test,y_train,clfs)</span><br><span class="line">clf = GradientBoostingClassifier(learning_rate=<span class="number">0.02</span>, subsample=<span class="number">0.5</span>, max_depth=<span class="number">6</span>, n_estimators=<span class="number">30</span>)</span><br><span class="line">clf.fit(New_train, y_train)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Machine learning</category>
      </categories>
      <tags>
        <tag>voting</tag>
        <tag>Stacking</tag>
        <tag>Blending</tag>
      </tags>
  </entry>
  <entry>
    <title>特征选择_1</title>
    <url>/2021/03/20/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9_1/</url>
    <content><![CDATA[<p>在数据预处理过程中，特征选择是一个重要的过程，选择出重要的特征可以加快模型训练速度。通常可以从以下两方面来选择特征：</p>
<blockquote>
<p>1.特征是否发散（对于样本区分作用的大小）<br>2.特征与标签的相关性</p>
</blockquote>
<span id="more"></span>
<p>特征选择的方法主要有3种：</p>
<blockquote>
<p>1.Filter Method：先根据统计量设置阈值选择特征，之后再训练模型。<br>2.Wrapper Method：把最终将要使用的模型的性能作为特征子集的评价标准，多次训练模型选择有利于模型性能的特征子集。<br>3.Embedding Method：将特征选择过程与模型训练过程融为一体，在模型训练的过程中自动进行特征选择。</p>
</blockquote>
<p>常用sklearn中的feature_selection库来进行特征选择。</p>
<h4 id="1-Fliter-过滤法"><a href="#1-Fliter-过滤法" class="headerlink" title="1. Fliter 过滤法:"></a>1. Fliter 过滤法:</h4><blockquote>
<p>Fliter的优点在于只训练一次模型，速度快。但是选择与标签相关性最强的特征子集不一定是最佳特征，甚至可能对结果负优化。</p>
</blockquote>
<h5 id="1-1-方差选择法"><a href="#1-1-方差选择法" class="headerlink" title="1.1 方差选择法"></a>1.1 方差选择法</h5><p>计算各个特征的方差，设置阈值，选择方差大于阈值的特征。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> VarianceThreshold</span><br><span class="line"><span class="comment">#参数threshold为方差的阈值</span></span><br><span class="line">VarianceThreshold(threshold=<span class="number">3</span>).fit_transform(iris.data)</span><br></pre></td></tr></table></figure>

<h5 id="1-2-Pearson相关系数法"><a href="#1-2-Pearson相关系数法" class="headerlink" title="1.2 Pearson相关系数法"></a>1.2 Pearson相关系数法</h5><p>计算各个特征对于标签的Pearson相关系数和p值，选择前k名的特征。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> pearsonr</span><br><span class="line"><span class="comment">#参数k为选择的特征个数</span></span><br><span class="line">SelectKBest(<span class="keyword">lambda</span> X, Y: array(<span class="built_in">map</span>(<span class="keyword">lambda</span> x:pearsonr(x, Y), X.T)).T, k=<span class="number">2</span>).fit_transform(iris.data, iris.target)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Pearson法的缺陷在于只对线性相关敏感，对非线性关系不敏感。</p>
</blockquote>
<h5 id="1-3-卡方检验-互信息法等方法"><a href="#1-3-卡方检验-互信息法等方法" class="headerlink" title="1.3 卡方检验\互信息法等方法"></a>1.3 卡方检验\互信息法等方法</h5><p>也是用来评价X与y的相关性，先构建评价函数，再选择前K名的特征。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#chi2</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> chi2</span><br><span class="line">SelectKBest(chi2, k=<span class="number">2</span>).fit_transform(iris.data, iris.target)</span><br><span class="line"></span><br><span class="line"><span class="comment">#MIC</span></span><br><span class="line"><span class="keyword">from</span> minepy <span class="keyword">import</span> MINE</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mic</span>(<span class="params">x, y</span>):</span></span><br><span class="line">     m = MINE()</span><br><span class="line">     m.compute_score(x, y)</span><br><span class="line">     <span class="keyword">return</span> (m.mic(), <span class="number">0.5</span>)</span><br><span class="line">SelectKBest(<span class="keyword">lambda</span> X, Y: array(<span class="built_in">map</span>(<span class="keyword">lambda</span> x:mic(x, Y), X.T)).T, k=<span class="number">2</span>).fit_transform(iris.data, iris.target)</span><br></pre></td></tr></table></figure>

<h4 id="2-Wrapper-包装法"><a href="#2-Wrapper-包装法" class="headerlink" title="2. Wrapper 包装法:"></a>2. Wrapper 包装法:</h4><blockquote>
<p>Wrapper的优点在于能够识别模型最适宜的特征子集，缺点在于训练多次模型，算法复杂性高，且特征子集不一定是<u>大多数解释变量</u>。</p>
</blockquote>
<p>Wrapper最具代表性的方法就是RFE递归消除特征法，即使用一个基模型来进行多轮训练，每轮训练都遍历所有特征，之后消除重要性(feature_importances_)低的特征，再基于新的特征集进行下一轮训练。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#RFE</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> RFE</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">rfe = RFE(estimator=LogisticRegression(), n_features_to_select=<span class="number">2</span>).fit_transform(iris.data, iris.target)</span><br><span class="line"></span><br><span class="line"><span class="comment">#RFECV</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> RFECV</span><br><span class="line">rfecv = RFECV(estimator=svc, step=<span class="number">1</span>, cv=StratifiedKFold(<span class="number">2</span>), scoring=<span class="string">&#x27;roc_auc&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h4 id="3-Embedded-嵌入法"><a href="#3-Embedded-嵌入法" class="headerlink" title="3. Embedded 嵌入法"></a>3. Embedded 嵌入法</h4><h5 id="3-1-基于惩罚项的特征选择法"><a href="#3-1-基于惩罚项的特征选择法" class="headerlink" title="3.1 基于惩罚项的特征选择法"></a>3.1 基于惩罚项的特征选择法</h5><p>使用带惩罚项的基模型，除了筛选出特征外，同时也进行了降维。由于L1正则化会产生稀疏权值矩阵，所以其自带特征选择的特性。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#L1正则</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectFromModel</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">SelectFromModel(LogisticRegression(penalty=<span class="string">&quot;l1&quot;</span>, C=<span class="number">0.1</span>)).fit_transform(iris.data, iris.target)</span><br><span class="line"></span><br><span class="line"><span class="comment">#L2正则</span></span><br><span class="line">SelectFromModel(LogisticRegression(penalty=<span class="string">&quot;l2&quot;</span>,threshold=<span class="number">0.5</span>, C=<span class="number">0.1</span>)).fit_transform(iris.data, iris.target)</span><br></pre></td></tr></table></figure>

<h5 id="3-2-基于树模型的特征选择法"><a href="#3-2-基于树模型的特征选择法" class="headerlink" title="3.2 基于树模型的特征选择法"></a>3.2 基于树模型的特征选择法</h5><p>树模型中GBDT也可用来作为基模型进行特征选择。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectFromModel</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier</span><br><span class="line">SelectFromModel(GradientBoostingClassifier()).fit_transform(iris.data, iris.target)</span><br></pre></td></tr></table></figure>

<h4 id="4-基于SHAP值的特征筛选"><a href="#4-基于SHAP值的特征筛选" class="headerlink" title="4. 基于SHAP值的特征筛选"></a>4. 基于SHAP值的特征筛选</h4><p>SHAP是由Shapley value启发的可加性解释模型。对于每条样本，每个特征都会对应一个SHAP value值体现其对结果的贡献。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> shap</span><br><span class="line"><span class="comment"># 创建模型解释器</span></span><br><span class="line">explainer_xgb = shap.TreeExplainer(model1)</span><br><span class="line">explainer_lgb = shap.TreeExplainer(model2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取训练集每个样本每个特征特征的SHAP值，并对特征进行整体的可视化</span></span><br><span class="line">shape_values = explainer_lgb.shap_values(data[cols])</span><br><span class="line">shap.summary_plot(shape_values, data[cols], plot_type=<span class="string">&#x27;bar&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h4 id="5-基于对抗验证-Adversarial-Validation-的特征筛选"><a href="#5-基于对抗验证-Adversarial-Validation-的特征筛选" class="headerlink" title="5. 基于对抗验证(Adversarial Validation)的特征筛选"></a>5. 基于对抗验证(Adversarial Validation)的特征筛选</h4><p>常用于训练集与测试集相差非常大的情况。实现步骤：<br>1.将训练集和测试集合并，分别打上0和1的标签。<br>2.构建模型进行训练，逐个将特征输入模型，记录AUC。<br>3.最后将AUC高的特征删除(将测试和训练样本差别很大的特征删除)，通过删掉这些特征实现模型效果提升。</p>
]]></content>
      <categories>
        <category>Feature engineering</category>
      </categories>
      <tags>
        <tag>Embedding</tag>
        <tag>Wapper</tag>
        <tag>Filter</tag>
      </tags>
  </entry>
</search>
